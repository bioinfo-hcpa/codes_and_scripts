---
title: "Adjunctive Taurine Therapy and Gut Microbiome Shifts in Adults with Type 2 Diabetes: A Randomized, Placebo-452led Trial"
author: "Dr. Otávio von Ameln Lovison"
date: "`r Sys.Date()`"
output:
  pdf_document:
    toc: yes
    toc_depth: 3
    latex_engine: xelatex
  word_document:
    toc: yes
    toc_depth: 5
  html_document:
    df_print: paged
    theme: cerulean
    highlight: haddock
    toc: yes
    toc_depth: 3
    toc_float:
      collapsed: no
      smooth_scroll: yes
    code_folding: show
always_allow_html: yes
header-includes:
  - \usepackage{float}
  - \usepackage{placeins}           # Para usar \FloatBarrier
  - \usepackage[font=small]{caption} # Legendas mais ajustadas
---

```{r setup, include = FALSE}
# Este primeiro chunk deve ser executado sempre que qualquer análise for ser realizada.
# Diretório de análise
path <- '/home/local.hcpa.ufrgs.br/olovison/Projects/Tasso_et_al_2025/Analysis'
knitr::opts_knit$set(root.dir = path)

# Configurações globais de chunk
knitr::opts_chunk$set(
  collapse   = TRUE,
  echo       = TRUE,
  message    = FALSE,
  warning    = FALSE,
  comment    = "#>",
  
  # Impressão de múltiplos plots em ordem
  fig.show   = "hold",     # <-- agrupa plots de um mesmo chunk
  fig.align  = "center",
  fig.width  = 8,          # redimensione a gosto (em polegadas)
  fig.height = 7,
  dpi        = 300,
  out.width  = "\\textwidth", # ajusta largura ao texto

  # Para forçar posição “aqui” dos floats
  fig.pos    = "H",         # requer \usepackage{float}
  results    = 'asis'
)
options(knitr.table.format = "latex")
```

# 0 - Prep
This investigation is a double-blind, randomized clinical trial assessing whether taurine supplementation alters the intestinal microbiota of adults with type 2 diabetes mellitus. It is embedded within a larger study (“Effect of taurine as an adjuvant to conventional diabetes therapy on glycemic, lipid, and inflammatory profiles”), and specifically targets gut microbial shifts induced by adjunctive taurine therapy.

Seventy-six stool samples are collected from 38 participants (17 in one arm, 21 in the other arm), each sampled at two timepoints (pre- and post-supplementation). Inclusion criteria require a clinical T2DM diagnosis ≥6 months, age 30–80 years, BMI ≥18.5 kg/m², stable antidiabetic regimen (≥3 months), no recent weight change, and HbA1c 7.5–10.5%. Key exclusions include recent use of herbal or antioxidant supplements, pregnancy/lactation, recent myocardial infarction, active neoplasia, chronic glucocorticoids, bariatric surgery, or insulin therapy . Randomization is stratified but concealed from participants and investigators.

Fecal samples are self-collected in sterile containers and held at 4 °C for up to 24 h before delivery, then transported on ice to the Bioinformatics Core (UPL/CPE/HCPA) . Consistency is recorded via the Bristol Stool Scale; samples are homogenized, aliquoted (4 × Eppendorf tubes), and stored at –80°C for up to two years. Microbial DNA is extracted using the QIAamp Power Fecal Pro DNA Kit per manufacturer’s protocol, ensuring high-quality yields for sequencing. Libraries are prepared using Illumina’s Nextera XT Index Kit v2 (Set A), and sequencing is performed on a MiSeq with the Reagent Kit v2 (Illumina). Targeted 16S rRNA amplification focuses on hypervariable regions V3–V4 (primers 341F/515R) and, in parallel, V3–V5 (primers 357F/926R), enabling comprehensive community profiling.


```{r download_main_data, eval=FALSE, echo=FALSE}
##Link for the repository containing the phyloseq object for all subsequent analyses.
#https://github.com/otaviolovison/Hemicell_timeseries_2025

# clean environment
rm(list = ls(all = TRUE))
```

# 0.1 Descriptive data
```{r desc_data, eval=TRUE, echo=FALSE}
#Se a tabela no final 'estourar' valores, verifique a fatorização e, se necessario, refaça após o exclude_vars
# Libraries
library(phyloseq)
library(microbiome)
library(dplyr)
library(magrittr)
library(stringr)
library(lubridate)
library(gtsummary)
library(tibble)
library(writexl)
library(kableExtra)

# 1) Diretório
path     <- '/home/local.hcpa.ufrgs.br/olovison/Projects/Tasso_et_al_2025/Analysis'
overview <- file.path(path, 'overview')
dir.create(overview, showWarnings = FALSE, recursive = TRUE)

# 2) Carrega o phyloseq original
ps0 <- readRDS('ps.dna.rds')

# 2.1) Extrai metadados e tabela
samdf <- microbiome::meta(ps0)
otu_tab <- as.data.frame(otu_table(ps0))

# 2.2) Transformando group em factor
samdf$Group <- as.factor(samdf$Group)

# 2.3) Define Timepoint pela primeira letra do SampleID
samdf <- samdf %>%
  mutate(
    Timepoint = case_when(
      grepl("^A", SampleID) ~ "Timepoint1",
      grepl("^B", SampleID) ~ "Timepoint2",
      TRUE                  ~ NA_character_
    ),
    Timepoint = factor(Timepoint, levels = c("Timepoint1","Timepoint2"))
  )

# 2.4) Calcula Days_since_start por PatientID
samdf <- samdf %>%
  mutate(Collection_date = dmy(Collection_date)) %>%
  group_by(PatientID) %>%
  arrange(Collection_date, .by_group = TRUE) %>%
  mutate(
    Days_since_start = as.numeric(Collection_date - min(Collection_date, na.rm = TRUE))
  ) %>%
  ungroup()

# 2.5) Cria Season (hemisfério sul)
samdf <- samdf %>%
  mutate(
    month = month(Collection_date),
    Season = case_when(
      month %in% c(12,1,2)   ~ "Summer",
      month %in% c(3,4,5)    ~ "Autumn",
      month %in% c(6,7,8)    ~ "Winter",
      month %in% c(9,10,11)  ~ "Spring",
      TRUE                   ~ NA_character_
    ),
    Season = factor(Season, levels = c("Summer","Autumn","Winter","Spring"))
  ) %>%
  select(-month)

# 2.6) Ajustando HbA1C
# 1–4) Clean and convert the HbA1c column in samdf
samdf <- samdf %>%
  # 1) Rename column
  rename(HbA1C = HbA1c) %>%
  # 2) Remove '%' and 3) replace comma with dot, then 4) convert to numeric
  mutate(
    HbA1C = str_remove_all(HbA1C, "%"),
    HbA1C = str_replace(HbA1C, ",", "."),
    HbA1C = as.numeric(HbA1C)
  )

# 2.7) Substitui vírgulas por pontos e converte para numérico
samdf <- samdf %>%
  mutate(
    `Body_weight` = as.numeric(str_replace_all(`Body_weight`, ",", ".")),
    BMI           = as.numeric(str_replace_all(BMI,           ",", "."))
  )

# 3) Salvar metadados ajustados
saveRDS(samdf, file.path(overview, 'adjusted_metadata.rds'))
write_xlsx(samdf, file.path(overview, 'adjusted_metadata.xlsx'))

# 3.1) Reconstrói ps0 com o metadata limpo
samdf <- as.data.frame(samdf)

# 2) pega a ordem dos SampleIDs na OTU table
sample_ids <- sample_names(ps0)  # ou rownames(otu_tab) se taxa_are_rows=FALSE

# 3) reordena TODO o samdf para casar com essa ordem
samdf <- samdf[ match(sample_ids, samdf$SampleID), ]

# 4) define os rownames de samdf como SampleID
rownames(samdf) <- samdf$SampleID

# 5) reconstrói o phyloseq com o tax_table original, os metadados reordenados e a otu_table
ps0 <- phyloseq(
  tax_table(ps0),
  sample_data(samdf),
  otu_table(otu_tab, taxa_are_rows = FALSE))

saveRDS(ps0, file.path(path, 'ps0.rds'))

# 3.2) Filtra somente Timepoint1 para a tabela
samdf <- samdf %>%
  filter(Timepoint == "Timepoint1")

# 4) Gera summary apenas com Timepoint1, estratificado por Group
summary_table <- tbl_summary(
  data     = samdf,
  by       = Group,
  include  = -c(PatientID, SampleID, Collection_date, Batch),
  missing      = "no",
  missing_text = "NA",
  statistic = list(
    all_continuous()  ~ "{mean} ± {sd}",
    all_categorical() ~ "{n}/{N} ({p}%)"
  ),
  label = list(
    HbA1C                                    ~ "HbA1C (%)",
    Sex                                      ~ "Sex",
    Age                                      ~ "Age (years)",
    Race                                     ~ "Race",
    Occupation                               ~ "Occupation",
    Body_weight                              ~ "Body Weight (kg)",
    BMI                                      ~ "Body Mass Index",
    BMI_classification                       ~ "BMI Classification",
    BMI_classification_.dichotomy.           ~ "BMI (dichotomous)",
    Hip_circumference                        ~ "Hip Circumference (cm)",
    Waist_circumference                      ~ "Waist Circumference (cm)",
    Heart_rate                               ~ "Heart Rate (bpm)",
    Systolic_blood_pressure                  ~ "Systolic BP (mmHg)",
    Diastolic_blood_pressure                 ~ "Diastolic BP (mmHg)",
    T2DM_diagnosis_time_.years.              ~ "T2DM Duration (years)",
    Hypertension                             ~ "Hypertension",
    Heart_disease                            ~ "Heart Disease",
    Dyslipidemia                             ~ "Dyslipidemia",
    Hypothyroidism                           ~ "Hypothyroidism",
    Renal_calculus                           ~ "Renal Calculus",
    Antidiabetics                            ~ "Antidiabetic Use",
    Biguanide                                ~ "Biguanide",
    Sulfonylureas                            ~ "Sulfonylureas",
    Sodium_glucose_cotransporter_type2_inhibitors ~ "SGLT2 Inhibitors",
    Glucagon.like.peptide.1                  ~ "GLP-1 Analogues",
    Dipeptidyl_peptidase_4_inhibitors        ~ "DPP-4 Inhibitors",
    Antihypertensives                        ~ "Antihypertensive Use",
    Angiotensin_II_receptor_antagonists      ~ "ARB Use",
    Calcium_channel_blockers                 ~ "Calcium Channel Blockers",
    Angiotensin_converting_enzyme_inhibitors ~ "ACE Inhibitors",
    Bet_adrenergic_.blockers                 ~ "β-Blockers",
    Diuretics                                ~ "Diuretics",
    Thiazide_diuretics                       ~ "Thiazide Diuretics",
    Nonsteroidal_anti_inflammatory_drugs     ~ "NSAIDs",
    Antiplatelet                             ~ "Antiplatelet Use",
    Antiplatelet_agents                      ~ "Clopidogrel",
    Hypercholesterolemia_treatment           ~ "Lipid-Lowering Rx",
    Inhibitors_of_hydroxymethylglutaryl_coenzyme_A_reductase ~ "Statins",
    Fibrates                                 ~ "Fibrates",
    Thyroid_hormones                         ~ "Thyroid Hormones",
    Antidepressants                          ~ "Antidepressant Use",
    Serotoni_and_norepinephrine_reuptake_inhibitors ~ "SNRI Use",
    norepinephrine_dopamine_reuptake_inhibitor      ~ "NDRI Use",
    Selective_serotonin_reuptake_inhibitors ~ "SSRI Use",
    Xanthine_oxidase_inhibitors              ~ "Xanthine Oxidase Inhibitors",
    Typical_antipsychotics                   ~ "Typical Antipsychotics",
    Anticonvulsants                          ~ "Anticonvulsant Use",
    Anticonvulsants.1                        ~ "Anticonvulsant (VPA/GPN)",
    Beta_2_agonist_bronchodilators           ~ "β2-Agonists",
    Antibiotic_use_.in_the_past_6_months.    ~ "Antibiotic Use (6 mo)",
    Daily_bowel_habits                       ~ "Daily Bowel Habits",
    Weekly_bowel_habits                      ~ "Weekly Bowel Habits",
    Bristol_stool_scale                      ~ "Bristol Stool Scale",
    Smoking                                  ~ "Smoking Status",
    Alcohol_consumption                      ~ "Alcohol Consumption",
    Physical_activity                        ~ "Physical Activity",
    Type_of_physical_activity                ~ "Type of Activity",
    Gastrointestinal_diseases_treatment      ~ "GI Disease Tx",
    Days_since_start                         ~ "Days Since First Sample",
    Season                                   ~ "Season (Southern Hemisphere)"
  )
) %>%
  add_p(
    test = list(
      all_categorical() ~ "fisher.test",
      all_continuous()  ~ "t.test"
    )
  ) %>%
  modify_header(
    label          ~ "**Variable**",
    all_stat_cols() ~ "**{level}**"
  ) %>%
  modify_spanning_header(
    all_stat_cols() ~ "**Group (N={N})**"
  ) %>%
  bold_labels()

# Impressão com NA nas células vazias
print(
  summary_table %>%
    as_kable_extra(
      booktabs    = TRUE,
      linesep     = "",
      caption     = "Descriptive Table: Timepoint1 Only",
      na          = "NA"
    ) %>%
    kable_styling(
      latex_options = c("hold_position","scale_down")
    )
)

# Clean up
rm(list = ls(all = TRUE))
```
\FloatBarrier

# 0.2 Features selection
## 0.2.1 Correlation matrix
To evaluate multicolinearity, let's calculate and plot the correlations.
```{r corr_mat, eval=TRUE, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center', fig.width=6, fig.height=4}
library(dplyr)
library(ggcorrplot)
library(caret)
library(writexl)
library(ggplot2)

# 1) Diretório (já criado antes)
path     <- '/home/local.hcpa.ufrgs.br/olovison/Projects/Tasso_et_al_2025/Analysis'
overview <- file.path(path, 'overview')

# 2) Carrega o phyloseq ajustado
ps0   <- readRDS("ps0.rds")

# 2.1) Extrai metadados
samdf <- microbiome::meta(ps0)

# 3) Seleciona variáveis contínuas e remove zero‐variance
num_df <- samdf %>% select(where(is.numeric))
nzv    <- nearZeroVar(num_df)
if(length(nzv) > 0) {
  message("Removing near zero vars: ", 
          paste(names(num_df)[nzv], collapse = ", "))
  num_df <- num_df[ , -nzv]
}

# 4) Calcula matriz de correlação
cor_mat <- cor(num_df, use = "pairwise.complete.obs")

# 5) Exporta matriz de correlação para Excel
write_xlsx(
  as.data.frame(cor_mat) %>% tibble::rownames_to_column("Variable"),
  file.path(overview, "correlation_matrix.xlsx")
)

# 6) Gera o heatmap
p_corr <- ggcorrplot(
  cor_mat,
  hc.order    = FALSE,
  lab         = TRUE,
  lab_size    = 3,
  outline.col = "white",
  title       = "Correlation Heatmap (numeric vars)"
) +
  theme_minimal(base_size = 7) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

# 7) Salva figura em PDF e PNG
ggsave(
  filename = file.path(overview, "correlation_heatmap.pdf"),
  plot     = p_corr,
  device   = cairo_pdf,
  width    = 8, height = 6
)
ggsave(
  filename = file.path(overview, "correlation_heatmap.png"),
  plot     = p_corr,
  width    = 8, height = 6, dpi = 300
)

# (Opcional) também exibe no RMarkdown
print(p_corr)
```
Since we have highly correlated features, we will remove Body weight, Waist Circumference, Hip Circumference and Weekly bowel habits.

## 0.2.2 Removing highly correlated variables
```{r rem_hi_corr_var, eval=TRUE, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center', fig.width=6, fig.height=4}
library(dplyr)
library(phyloseq)

# 1) Remove as variáveis altamente correlacionadas do samdf
samdf2 <- samdf %>%
  select(-Weekly_bowel_habits,
         -Waist_circumference,
         -Hip_circumference,
         -Body_weight)

# 2) Reconstrói o objeto phyloseq com samdf2
# Extrai as tabelas originais
otu_tab_old <- otu_table(ps0)
tax_tab     <- tax_table(ps0)

# Prepara o novo sample_data
samdf2_df <- as.data.frame(samdf2)
rownames(samdf2_df) <- samdf2_df$SampleID
sample_data_new <- sample_data(samdf2_df)

# Monta o novo ps0
ps0 <- phyloseq(
  tax_tab,
  sample_data_new,
  otu_tab_old
)

# 3) (Opcional) Salva o novo phyloseq
saveRDS(ps0, file.path(path, "ps0_filtered_vars.rds"))
```

## 0.3 Data preparation
### 0.3.1 Data prep plot
```{r data_prep_plot, eval=TRUE, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center', fig.width=6, fig.height=4,  fig.cap='Prevalence vs. Total Abundance (ASVs) with filtering cutoff'}
library(phyloseq)
library(ggplot2)

# 1) Carrega objeto e dados
ps.dna <- readRDS("ps0_filtered_vars.rds")
ps0.dna <- subset_taxa(ps.dna,
                       !is.na(Phylum) &
                       !Phylum %in% c("", "uncharacterized", "NA"))
prevalenceThreshold <- 0.13 * nsamples(ps0.dna)

# 2) Prevalence x Abundance
prev_counts <- apply(otu_table(ps0.dna) > 0,
                     ifelse(taxa_are_rows(ps0.dna), 1, 2),
                     sum)
abund_counts <- taxa_sums(ps0.dna)
prevdf_asv <- data.frame(Prevalence = prev_counts,
                         Abundance  = abund_counts)

# 3) Plot
ggplot(prevdf_asv, aes(x = Prevalence, y = Abundance)) +
  geom_point(alpha = 0.4) +
  geom_vline(xintercept = prevalenceThreshold,
             linetype = "dashed", color = "red") +
  labs(
    title    = "Prevalence vs. Total Abundance (ASVs)",
    subtitle = paste0("Filtering cutoff = ", prevalenceThreshold, " samples"),
    x        = "Number of samples in which ASV appears",
    y        = "Total read count"
  ) +
  theme_bw(base_size = 12)
```

### 0.3.2 Data preparation
```{r data_prep_table, eval=TRUE, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
library(phyloseq)
library(dplyr)
library(tibble)
library(knitr)
library(kableExtra)

# 1) Carrega e filtra o objeto ps
ps0.dna      <- readRDS("ps0.rds")
ps0.filtered <- subset_taxa(ps0.dna,
                            !is.na(Phylum) &
                            !Phylum %in% c("", "uncharacterized", "NA"))

# 2) Define thresholds
prevalenceThreshold <- 0.13 * nsamples(ps0.filtered)                
totalReads          <- sum(taxa_sums(ps0.filtered))
abundanceThreshold  <- 0.0001 * totalReads                           # 0.01% do total de reads

# 3) Filtra ASV
keepASV   <- taxa_sums(ps0.filtered) >= abundanceThreshold &
             apply(otu_table(ps0.filtered) > 0,
                   ifelse(taxa_are_rows(ps0.filtered), 1, 2),
                   sum) >= prevalenceThreshold
ps1.dna   <- prune_taxa(keepASV, ps0.filtered)

# 4) Filtra Genus
 ps0.genus      <- tax_glom(ps0.filtered, "Genus",  NArm = FALSE)
 keepGenus      <- taxa_sums(ps0.genus) >= abundanceThreshold &
                   apply(otu_table(ps0.genus) > 0,
                         ifelse(taxa_are_rows(ps0.genus), 1, 2),
                         sum) >= prevalenceThreshold
ps1.dna.genus  <- prune_taxa(keepGenus, ps0.genus)
 
# 5) Filtra Family
ps0.family     <- tax_glom(ps0.filtered, "Family", NArm = FALSE)
keepFamily     <- taxa_sums(ps0.family) >= abundanceThreshold &
                   apply(otu_table(ps0.family) > 0,
                         ifelse(taxa_are_rows(ps0.family), 1, 2),
                         sum) >= prevalenceThreshold
ps1.dna.family <- prune_taxa(keepFamily, ps0.family)
 
# 6) Filtra Phylum
ps0.phyla      <- tax_glom(ps0.filtered, "Phylum", NArm = FALSE)
keepPhylum     <- taxa_sums(ps0.phyla) >= abundanceThreshold &
                   apply(otu_table(ps0.phyla) > 0,
                         ifelse(taxa_are_rows(ps0.phyla), 1, 2),
                         sum) >= prevalenceThreshold
 ps1.dna.phy    <- prune_taxa(keepPhylum, ps0.phyla)

# 7) Salva objetos
saveRDS(ps1.dna,        "ps1.dna.rds")
saveRDS(ps1.dna.genus,  "ps1.dna.genus.rds")
saveRDS(ps1.dna.family, "ps1.dna.family.rds")
saveRDS(ps1.dna.phy,    "ps1.dna.phy.rds")

 # 8) Monta e exibe tabela
counts <- tibble(
   Level      = c("ASV", "Genus", "Family", "Phylum"),
   Before     = c(ntaxa(ps0.filtered), ntaxa(ps0.genus),
                  ntaxa(ps0.family),    ntaxa(ps0.phyla)),
   After      = c(ntaxa(ps1.dna),      ntaxa(ps1.dna.genus),
                  ntaxa(ps1.dna.family),ntaxa(ps1.dna.phy)),
   `Prev Thres`  = round(prevalenceThreshold, 1),
   `Abund Thres` = round(abundanceThreshold, 0)
 )

#counts

counts %>%
   kable(
     caption = "Taxa before/after prevalence \\& abundance filtering",
     digits  = 0,
     booktabs= TRUE
   ) %>%
   kable_classic(full_width = FALSE, position = "center") %>%
   column_spec(2:3, width = "1.5cm") %>%
   column_spec(4:5, width = "1.2cm")

# 9) Limpa ambiente
rm(list = ls(all = TRUE))
```
We filtered out taxa lacking phylum-level annotations, applied a 13% prevalence filter, 0.01% abundance filter, and aggregated taxa at the phylum, family, and genus levels.

## 0.4 Feature importance
### 0.4.1 - Principal Variance Component Analysis (PVCA)
```{r feat_imp_PVCA, eval=TRUE, echo=FALSE, message=FALSE, warning=FALSE, fig.align='center', fig.width=6, fig.height=4}
# PVCA: Principal Variance Component Analysis
#O PVCA (Principal Variance Component Analysis) combina redução de dimensionalidade (via PCA) com análise de componentes de variância (via modelos mistos) para estimar, de forma quantitativa, “quanto” da variabilidade total dos seus dados de perfil microbiano é atribuível a cada metadado (batch, Group, Timepoint, Season, etc).
#O PVCA foi desenvolvido para quantificar, de forma agregada, quanto da variabilidade total do seu perfil microbiano é explicada por cada fator (e pela variância residual). 
#Use PVCA como primeiro passo: identifique quais fatores (e.g. Season, Group, Batch, Sex) têm maior “peso” na comunidade. Isso orienta quais variáveis de metadados você deve testar prioritariamente nos modelos. Em seguida, ajuste um modelo linear misto completo (incluindo esses fatores) e avalie:

#Importância individual por estimativa de coeficiente e p-valor.
#Multicolinearidade (VIF), para não manter fatores que competem entre si.
#Seleção automatizada (LASSO, seleção passo-a-passo ou técnicas de penalização) se tiver muitas covariáveis.

library(phyloseq)
library(microbiome)
library(variancePartition)
library(Biobase)
library(dplyr)
library(ggplot2)

# 1) Carrega phyloseq ajustado
ps   <- readRDS("ps1.dna.rds")
meta  <- as(sample_data(ps), "data.frame")
otu   <- as(otu_table(ps),   "matrix")
if(taxa_are_rows(ps)) otu <- t(otu)

# 2) Normaliza por CLR e prepara matriz de expressão
otu_norm <- microbiome::transform(ps, "clr") %>%
  otu_table() %>% as("matrix")
expr     <- t(otu_norm)  # ExpressionSet expects samples × features

# 3) Define a fórmula de efeitos aleatórios sem interações
#    Aqui incluí SubjectID como aleatório e Batch e Season como aleatórios também,
#    mas *sem* PatientID:Season
formula <- ~ Group + Sex + Age + Race + BMI_classification + Hypertension +
  Dyslipidemia + Hypothyroidism + Antibiotic_use_.in_the_past_6_months. +
  Alcohol_consumption + Gastrointestinal_diseases_treatment +  Season

# 4) Roda a modelagem
vp <- fitExtractVarPartModel(expr, formula, meta)

# 5) Plot das proporções de variância com eixo X rotacionado
p_vp <- plotVarPart(vp) +
  ggtitle("Variance partitioning (variancePartition)") +
  theme_minimal(base_size = 10) +
  theme(
    axis.text.x = element_text(angle = 45, hjust = 1)
  )

# 6) Salva figuras
ggsave("variancePartition_components.pdf", p_vp, path = "overview",
       device = cairo_pdf, width = 7, height = 5)
ggsave("variancePartition_components.png", p_vp, path = "overview",
       dpi = 300, width = 7, height = 5)

# Exibe no documento
print(p_vp)

# 9) Limpa ambiente
rm(list = ls(all = TRUE))
```
We will not use 'Season' as a variable for modeling since it does not showed importance as a feature in this data.
### 0.4.2 Autocorrelation
Checking autocorrelation among samples from the same patient over time.
```{r autocorr, eval=TRUE, echo=FALSE, message=FALSE, warning=FALSE, fig.cap='Spaghetti plots of PC1, PC2 and Shannon index over Age by Group'}
set.seed(123)
library(phyloseq)
library(microbiome)
library(compositions)
library(nlme)
library(ggplot2)
library(dplyr)
library(tibble)
library(broom)

path     <- '/home/local.hcpa.ufrgs.br/olovison/Projects/Tasso_et_al_2025/Analysis'
autocorr <- file.path(path, "autocorrelation")
dir.create(autocorr, showWarnings = FALSE, recursive = TRUE)

ps   <- readRDS("ps1.dna.rds")

# 1) Monta meta_df sem duplicar SampleID
meta_df <- sample_data(ps) %>%
  as("data.frame") %>%
  # se já existir coluna SampleID, remove antes:
  { if("SampleID" %in% colnames(.)) select(., -SampleID) else . } %>%
  rownames_to_column("SampleID") %>%
  mutate(
    Days   = as.numeric(Days_since_start),
    Group  = factor(Group),
    PatientID = factor(PatientID)
  )

# 2) ILR + PCA
abun <- as.matrix(otu_table(ps))
if(taxa_are_rows(ps)) abun <- t(abun)
abun[abun==0] <- 0.5
ilr_mat <- compositions::ilr(abun)
pca_res <- prcomp(ilr_mat, center=FALSE, scale.=FALSE)
var_pct <- pca_res$sdev^2 / sum(pca_res$sdev^2)

scores_df <- pca_res$x[,1:2] %>%
  as.data.frame() %>%
  rownames_to_column("SampleID") %>%
  rename(PC1 = 2, PC2 = 3) %>%
  left_join(meta_df, by = "SampleID")

# 3) Spaghetti plots vs Days
for(PC in c("PC1","PC2")){
  p <- ggplot(scores_df, aes_string(x="Days", y=PC, group="PatientID", color="Group")) +
    geom_line(alpha=0.5) + geom_point(size=2) +
    labs(
      x="Days since first sample",
      y=sprintf("%s (%.1f%%)", PC, var_pct[as.integer(substr(PC,3,3))]*100),
      title=sprintf("%s over time", PC)
    ) +
    theme_bw(base_size=12)
  ggsave(file.path(autocorr, paste0(PC, "_spaghetti.pdf")), p,
         width=6, height=4, dpi=300)
  print(p)
}

# Shannon
shannon_df <- meta_df %>%
  bind_cols(estimate_richness(ps, measures="Shannon") %>% rownames_to_column("SampleID")) %>%
  rename(Shannon = Shannon)

p_sh <- ggplot(shannon_df, aes(x=Days, y=Shannon, group=PatientID, color=Group)) +
  geom_line(alpha=0.5) + geom_point(size=2) +
  labs(x="Days since first sample", y="Shannon index", title="Shannon over time") +
  theme_bw(base_size=12)
ggsave(file.path(autocorr, "Shannon_spaghetti.pdf"), p_sh,
       width=6, height=4, dpi=300)
print(p_sh)

# 4) AIC AR(1) vs none
diag_df <- bind_rows(
  lapply(c("PC1","PC2"), function(PC) {
    df <- filter(scores_df, !is.na(.data[[PC]]))
    m0 <- lme(as.formula(paste(PC, "~ Days*Group")),
              random=~1|PatientID, data=df, method="REML")
    m1 <- update(m0, correlation=corCAR1(form=~Days|PatientID))
    tibble(
      feature      = PC,
      AIC_noAR1    = AIC(m0),
      AIC_withAR1  = AIC(m1),
      deltaAIC     = AIC(m0) - AIC(m1)
    )
  }),
  {
    df <- filter(shannon_df, !is.na(Shannon))
    m0 <- lme(Shannon ~ Days*Group, random=~1|PatientID,
              data=df, method="REML")
    m1 <- update(m0, correlation=corCAR1(form=~Days|PatientID))
    tibble(
      feature      = "Shannon",
      AIC_noAR1    = AIC(m0),
      AIC_withAR1  = AIC(m1),
      deltaAIC     = AIC(m0) - AIC(m1)
    )
  }
)

p_aic <- ggplot(diag_df, aes(x=reorder(feature, deltaAIC), y=deltaAIC)) +
  geom_col(fill="steelblue") + coord_flip() +
  labs(x="Feature", y=expression(Delta~AIC),
       title="ΔAIC: AR(1) vs none") +
  theme_minimal(base_size=10)
ggsave(file.path(autocorr, "deltaAIC_ar1_vs_none.pdf"), p_aic,
       width=5, height=3, dpi=300)
print(p_aic)

#diag_df

knitr::kable(diag_df, digits=1,
             caption="AIC comparison: correlation vs no‐correlation")

# --- 5) Clean up -----------------------------------------------------------
rm(list = ls())
```
The models with autocorrelation structure performed worse (deltaAIC negative) and the autocorrelation structure will not be used. This may happen when you have few and distant timepoints.  
\FloatBarrier

# 0.5 Checking outliers
## 0.5.1 Outliers by sample size and composition
```{r outliers_size_comp, eval=TRUE, echo=FALSE, message=FALSE, warning=FALSE,fig.align='center', fig.width=6, fig.height=4}
# Load libraries
library(broom)
library(dplyr)
library(kableExtra)
library(ggplot2)
library(forcats)
library(phyloseq)

# 1) Output directory
path         <- '/home/local.hcpa.ufrgs.br/olovison/Projects/Tasso_et_al_2025/Analysis'
overview_dir <- file.path(path, 'overview')
dir.create(overview_dir, showWarnings = FALSE, recursive = TRUE)

# 2) Carrega objeto phyloseq principal e aglomerações taxonômicas
ps_ASV    <- readRDS(file.path(path, 'ps1.dna.rds'))
ps_phylum <- tax_glom(ps_ASV, 'Phylum', NArm = TRUE)
ps_family <- tax_glom(ps_ASV, 'Family', NArm = TRUE)
ps_genus  <- tax_glom(ps_ASV, 'Genus', NArm = TRUE)

# 3) Metadados + profundidade
meta <- data.frame(sample_data(ps_ASV)) %>%
  mutate(
    Sample      = sample_names(ps_ASV),
    Depth       = sample_sums(ps_ASV),
    Group = factor(Group, levels = c('452','151')),
    Timepoint = factor(Timepoint, levels = c("Timepoint1","Timepoint2"))
  )

# 4) ANOVA two‑way e tabela tidy
depth_aov <- aov(Depth ~ Group * Timepoint, data = meta)
anova_tbl <- broom::tidy(depth_aov)
colnames(anova_tbl)[1:6] <- c('Term','Df','Sum Sq','Mean Sq','F value','Pr(>F)')

# 5) Formatação com kableExtra
anova_tbl %>%
  kable(caption = 'Two‑way ANOVA on Sequencing Depth', digits = 3, booktabs = TRUE) %>%
  kable_styling(latex_options = c('hold_position','scale_down')) %>%
  print()

#anova_tbl

# 6) Boxplot de profundidade por Group e Timepoint
p0 <- ggplot(meta, aes(x = Group, y = Depth, fill = Group)) +
  geom_boxplot(width = 0.6) +
  scale_fill_manual(values = c('452' = 'darkgreen',
                               '151' = 'magenta')) +
  facet_grid(. ~ Timepoint) +                         # <- aqui
  labs(title = 'Library Depth by Group and Timepoint',
       x = 'Group', y = 'Sequencing Depth') +
  theme_bw() +
  theme(legend.position = 'none')

ggsave(file.path(overview_dir, 'fig0_depth_boxplot.pdf'),
       p0, width = 180, height = 120, units = 'mm', dpi = 300)

print(p0)

# 7) Barchart de library size por amostra
p1 <- ggplot(meta, aes(x = Sample, y = Depth, fill = Group)) +
  geom_bar(stat = 'identity') +
  scale_fill_manual(values = c('452' = 'darkgreen', '151' = 'magenta')) +
  labs(title = 'Library Size by Sample', x = 'Sample ID', y = 'Sequencing Depth', fill = 'Group') +
  theme_bw() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1), legend.position = 'top')
ggsave(file.path(overview_dir, 'fig1_library_size.pdf'), p1, width = 180, height = 120, units = 'mm', dpi = 300)
print(p1)

# 8) Função para Figures 2–5: top taxa (suporta ASV alias)
taxa_plot <- function(ps_obj, level_col, top_n, fig_num) {
  ps_ra <- transform_sample_counts(ps_obj, function(x) x / sum(x))
  df    <- psmelt(ps_ra)
  # se usar level_col='ASV', renomeia coluna OTU para ASV
  if (level_col == 'ASV') df <- rename(df, ASV = OTU)
  # identifica coluna real para agrupamento
  real_col <- if (level_col == 'ASV') 'ASV' else level_col
  # calcula top taxa
  top_taxa <- df %>%
    group_by(.data[[real_col]]) %>%
    summarize(mean_abund = mean(Abundance), .groups = 'drop') %>%
    arrange(desc(mean_abund)) %>%
    slice_head(n = top_n) %>%
    pull(real_col)
  # agrega para plot
  df_plot <- df %>%
    mutate(Taxa = as.character(.data[[real_col]]), Taxa = ifelse(Taxa %in% top_taxa, Taxa, 'Other')) %>%
    group_by(Sample, Group, Timepoint, Taxa) %>%
    summarize(Abundance = sum(Abundance), .groups = 'drop') %>%
    mutate(Taxa = fct_reorder(Taxa, Abundance, .fun = mean))
  
  p <- ggplot(df_plot, aes(x = Sample, y = Abundance, fill = Taxa)) +
    geom_bar(stat = 'identity') +
    facet_wrap(vars(Timepoint, Group), ncol = 2, scales = 'free_x') +
    labs(title = paste0('Figure ', fig_num, ': Relative Abundance at ', level_col),
         x = 'Sample ID', y = 'Relative Abundance', fill = level_col) +
    theme_bw() + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust = 1, size = 6),
                        strip.background = element_rect(fill = 'white'),
                        strip.text = element_text(face = 'bold'),
                        legend.position = 'right')
  # salva e imprime
  fname <- paste0('fig', fig_num, '_', tolower(level_col), '.pdf')
  ggsave(file.path(overview_dir, fname), p, width = 180, height = 120, units = 'mm', dpi = 300)
  print(p)
}

# 9) Figures 2–5
taxa_plot(ps_phylum, 'Phylum', 10, '2')
taxa_plot(ps_family, 'Family', 10, '3')
taxa_plot(ps_genus,  'Genus',  20, '4')
taxa_plot(ps_ASV,    'ASV',    20, '5')

# 10) Limpa ambiente
rm(list = ls(all = TRUE))
```
The samples B09 and B37 are sample size outliers and we will keep an eye on them.
\FloatBarrier

# 1.0 Microbiome overview
## 1.1 Ajusting for calculations and tables
Here we transform the data in relative abundances for proper evaluation.
```{r microbiome_overview, eval=T, echo=F}
library(writexl)
path <- '/home/local.hcpa.ufrgs.br/olovison/Projects/Tasso_et_al_2025/Analysis'
overview = paste(path,"/overview/",sep = "")

ps0.dna <- readRDS("ps1.dna.rds")

#Aglomerações
ps.dna.phy <- tax_glom(ps0.dna, "Phylum", NArm = TRUE)
ps.dna.family <- tax_glom(ps0.dna, "Family", NArm = TRUE)
ps.dna.genus <- tax_glom(ps0.dna, "Genus", NArm = TRUE)

#ASV level
ps.ra <- transform_sample_counts(ps0.dna, function(x) x/sum(x))

#Phylum level
taxa_names(ps.dna.phy) <- tax_table(ps.dna.phy)[,2]
ps.phy.ra <- transform_sample_counts(ps.dna.phy, function(x) x/sum(x))

#Family level
taxa_names(ps.dna.family) <- tax_table(ps.dna.family)[,5]
ps.family.ra <- transform_sample_counts(ps.dna.family, function(x) x/sum(x))

#Genus level
#taxa_names(ps.dna.genus) <- tax_table(ps.dna.genus)[,6]
ps.genus.ra <- transform_sample_counts(ps.dna.genus, function(x) x/sum(x))
genus.melt <- psmelt(ps.genus.ra)
```

### 1.1.1 Dominant taxa
#### Tables
The distribution of the reads are here summarized on phylum, family and genus level. 
```{r ov_microbiome_tables, eval=T, echo=F}
df2 <- data.frame(tax_table(ps.dna.phy), taxprc = 100*taxa_sums(ps.phy.ra)/length(sample_names(ps.phy.ra)))
df3 <- data.frame(tax_table(ps.dna.family), taxprc = 100*taxa_sums(ps.family.ra)/length(sample_names(ps.family.ra)))
df4 <- data.frame(tax_table(ps.dna.genus),taxprc = 100*taxa_sums(ps.genus.ra)/length(sample_names(ps.genus.ra)))
df5 <- data.frame(tax_table(ps0.dna),taxprc = 100*taxa_sums(ps.ra)/length(sample_names(ps.ra)))

df.count <- data.frame(Included = c("All", "> 0.01%", "> 0.1%","> 1%"),
                          Phylum = c(nrow(df2),sum(df2$taxprc > 0.01),sum(df2$taxprc > 0.1),sum(df2$taxprc > 1)),
                          Family = c(nrow(df3),sum(df3$taxprc > 0.01),sum(df3$taxprc > 0.1),sum(df3$taxprc > 1)),
                          Genus = c(nrow(df4),sum(df4$taxprc > 0.01),sum(df4$taxprc > 0.1),sum(df4$taxprc > 1)),
                          ASV = c(nrow(df5),sum(df5$taxprc > 0.01),sum(df5$taxprc > 0.1),sum(df5$taxprc > 1)))

# Se quiser exportar para um arquivo Excel
FileName <- paste(overview,"/Abundance of phyla, family, genera and ASV in microbiome samples.xlsx", sep = "")
write_xlsx(df.count,FileName)

# Se quiser exportar para um arquivo Excel
FileName <- paste(overview,"/Average abundance according to genus.xlsx", sep = "")
write_xlsx(df4,FileName)

# Se quiser exportar para um arquivo Excel
FileName <- paste(overview,"/Average abundance according to family.xlsx", sep = "")
write_xlsx(df3,FileName)

# Se quiser exportar para um arquivo Excel
FileName <- paste(overview,"/Average abundance according to phylum.xlsx", sep = "")
write_xlsx(df2,FileName)

# Count of ASV and taxa in samples
kable(df.count, row.names = F,digits = 1, caption = 'Abundance of phyla, family, genera and ASV in microbiome samples')%>% 
  kable_classic(full_width = F, position = "left")%>%  
  kable_styling(latex_options = c("scale_down", "hold_position"))

# Top 6 dominating phyla (prc abundance)
kable(head(df2[order(df2$taxprc,decreasing = T),c("Kingdom","Phylum","taxprc")]), row.names = F,digits = 1, caption = 'Average abundance according to phylum',col.names = c("Kingdom","Phylum","Abundance (%)"))%>% 
  kable_classic(full_width = F, position = "left")%>%  
  kable_styling(latex_options = c("scale_down", "hold_position"))

# Top 6 dominating family (prc abundance)
kable(head(df3[order(df3$taxprc,decreasing = T),c("Kingdom","Phylum","Family", "taxprc")]), row.names = F,digits = 1, caption = 'Average abundance according to family',col.names = c("Kingdom","Phylum", "Family", "Abundance (%)"))%>% 
  kable_classic(full_width = F, position = "left")%>%  
  kable_styling(latex_options = c("scale_down", "hold_position"))

# Top 6 dominating (genera prc abundance)
kable(head(df4[order(df4$taxprc,decreasing = T),c("Kingdom","Phylum","Class","Order","Family","Genus","taxprc")]), row.names = F,digits = 1, caption = 'Average abundance according to genus',col.names = c("Kingdom","Phylum","Class","Order","Family","Genus","Abundance (%)"))%>% 
  kable_classic(full_width = F, position = "left")%>%  
  kable_styling(latex_options = c("scale_down", "hold_position"))

# clean environment
rm(list = ls(all = TRUE))
```
\FloatBarrier

### 1.1.2 Distribution of taxa in 452 samples
```{r 452_dist1, eval=T, echo=F}
path <- '/home/local.hcpa.ufrgs.br/olovison/Projects/Tasso_et_al_2025/Analysis'
over_group_timepoint = paste(path,"/overview_by_group_and_timepoint/",sep = "")
dir.create(over_group_timepoint)

ps <- readRDS("ps1.dna.rds")
ps.452 <- subset_samples(ps, Group=='452')

#Aglomerações
ps.452.phy <- tax_glom(ps.452, "Phylum", NArm = TRUE)
ps.452.family <- tax_glom(ps.452, "Family", NArm = TRUE)
ps.452.genus <- tax_glom(ps.452, "Genus", NArm = TRUE)

#ASV level
ps.452.ra <- transform_sample_counts(ps.452, function(x) x/sum(x))

#Phylum level
taxa_names(ps.452.phy) <- tax_table(ps.452.phy)[,2]
ps.452.phy.ra <- transform_sample_counts(ps.452.phy, function(x) x/sum(x))

#Family level
taxa_names(ps.452.family) <- tax_table(ps.452.family)[,5]
ps.452.family.ra <- transform_sample_counts(ps.452.family, function(x) x/sum(x))

#Genus level
#taxa_names(ps.dna.genus) <- tax_table(ps.dna.genus)[,6]
ps.452.genus.ra <- transform_sample_counts(ps.452.genus, function(x) x/sum(x))
ps.452.genus.melt <- psmelt(ps.452.genus.ra)

df2 <- data.frame(tax_table(ps.452.phy), taxprc = 100*taxa_sums(ps.452.phy.ra)/length(sample_names(ps.452.phy.ra)))
df3 <- data.frame(tax_table(ps.452.family), taxprc = 100*taxa_sums(ps.452.family.ra)/length(sample_names(ps.452.family.ra)))
df4 <- data.frame(tax_table(ps.452.genus),taxprc = 100*taxa_sums(ps.452.genus.ra)/length(sample_names(ps.452.genus.ra)))
df5 <- data.frame(tax_table(ps.452),taxprc = 100*taxa_sums(ps.452.ra)/length(sample_names(ps.452.ra)))

df.count <- data.frame(Included = c("All", "> 0.01%", "> 0.1%","> 1%"),
                          Phylum = c(nrow(df2),sum(df2$taxprc > 0.01),sum(df2$taxprc > 0.1),sum(df2$taxprc > 1)),
                          Family = c(nrow(df3),sum(df3$taxprc > 0.01),sum(df3$taxprc > 0.1),sum(df3$taxprc > 1)),
                          Genus = c(nrow(df4),sum(df4$taxprc > 0.01),sum(df4$taxprc > 0.1),sum(df4$taxprc > 1)),
                          ASV = c(nrow(df5),sum(df5$taxprc > 0.01),sum(df5$taxprc > 0.1),sum(df5$taxprc > 1)))

# Count of ASV and taxa in 452 samples
kable(df.count, row.names = F,digits = 1, caption = 'Abundance of phyla, family, genera and ASV in 452 samples')%>% 
  kable_classic(full_width = F, position = "left")%>%  
  kable_styling(latex_options = c("scale_down", "hold_position"))

# Se quiser exportar para um arquivo Excel
FileName <- paste(over_group_timepoint,"/Abundance of phyla, family, genera and ASV in 452 samples.xlsx", sep = "")
write_xlsx(df.count,FileName)

# Top 6 dominating phyla (prc abundance)
kable(head(df2[order(df2$taxprc,decreasing = T),c("Kingdom","Phylum","taxprc")]), row.names = F,digits = 1, caption = 'Average abundance according to phylum in 452 samples',col.names = c("Kingdom","Phylum","Abundance (%)"))%>% 
  kable_classic(full_width = F, position = "left")%>%  
  kable_styling(latex_options = c("scale_down", "hold_position"))

# Se quiser exportar para um arquivo Excel
FileName <- paste(over_group_timepoint,"/Average abundance according to phylum in 452 samples.xlsx", sep = "")
write_xlsx(df2,FileName)

# Top 6 dominating family (prc abundance)
kable(head(df3[order(df3$taxprc,decreasing = T),c("Kingdom","Phylum","Family", "taxprc")]), row.names = F,digits = 1, caption = 'Average abundance according to family in 452 samples',col.names = c("Kingdom","Phylum", "Family", "Abundance (%)"))%>% 
  kable_classic(full_width = F, position = "left")%>%  
  kable_styling(latex_options = c("scale_down", "hold_position"))

# Se quiser exportar para um arquivo Excel
FileName <- paste(over_group_timepoint,"/Average abundance according to family in 452 samples.xlsx", sep = "")
write_xlsx(df3,FileName)

# Top 6 dominating (genera prc abundance)
kable(head(df4[order(df4$taxprc,decreasing = T),c("Kingdom","Phylum","Class","Order","Family","Genus","taxprc")]), row.names = F,digits = 1, caption = 'Average abundance according to genus in 452 samples',col.names = c("Kingdom","Phylum","Class","Order","Family","Genus","Abundance (%)"))%>% 
  kable_classic(full_width = F, position = "left")%>%  
  kable_styling(latex_options = c("scale_down", "hold_position"))

# Se quiser exportar para um arquivo Excel
FileName <- paste(over_group_timepoint,"/Average abundance according to genus in 452 samples.xlsx", sep = "")
write_xlsx(df4,FileName)

# clean environment
#rm(list = ls(all = TRUE))
```
\FloatBarrier

### 1.1.3 Distribution of taxa in 151 samples
```{r beta_dis, eval=T, echo=F}
path <- '/home/local.hcpa.ufrgs.br/olovison/Projects/Tasso_et_al_2025/Analysis'
over_group_timepoint = paste(path,"/overview_by_group_and_timepoint/",sep = "")

ps <- readRDS("ps1.dna.rds")
ps.beta <- subset_samples(ps, Group=='151')

#Aglomerações
ps.beta.phy <- tax_glom(ps.beta, "Phylum", NArm = TRUE)
ps.beta.family <- tax_glom(ps.beta, "Family", NArm = TRUE)
ps.beta.genus <- tax_glom(ps.beta, "Genus", NArm = TRUE)

#ASV level
ps.beta.ra <- transform_sample_counts(ps.beta, function(x) x/sum(x))

#Phylum level
taxa_names(ps.beta.phy) <- tax_table(ps.beta.phy)[,2]
ps.beta.phy.ra <- transform_sample_counts(ps.beta.phy, function(x) x/sum(x))

#Family level
taxa_names(ps.beta.family) <- tax_table(ps.beta.family)[,5]
ps.beta.family.ra <- transform_sample_counts(ps.beta.family, function(x) x/sum(x))

#Genus level
#taxa_names(ps.dna.genus) <- tax_table(ps.dna.genus)[,6]
ps.beta.genus.ra <- transform_sample_counts(ps.beta.genus, function(x) x/sum(x))
ps.beta.genus.melt <- psmelt(ps.beta.genus.ra)

df2 <- data.frame(tax_table(ps.beta.phy), taxprc = 100*taxa_sums(ps.beta.phy.ra)/length(sample_names(ps.beta.phy.ra)))
df3 <- data.frame(tax_table(ps.beta.family), taxprc = 100*taxa_sums(ps.beta.family.ra)/length(sample_names(ps.beta.family.ra)))
df4 <- data.frame(tax_table(ps.beta.genus),taxprc = 100*taxa_sums(ps.beta.genus.ra)/length(sample_names(ps.beta.genus.ra)))
df5 <- data.frame(tax_table(ps.beta),taxprc = 100*taxa_sums(ps.beta.ra)/length(sample_names(ps.beta.ra)))

df.count <- data.frame(Included = c("All", "> 0.01%", "> 0.1%","> 1%"),
                          Phylum = c(nrow(df2),sum(df2$taxprc > 0.01),sum(df2$taxprc > 0.1),sum(df2$taxprc > 1)),
                          Family = c(nrow(df3),sum(df3$taxprc > 0.01),sum(df3$taxprc > 0.1),sum(df3$taxprc > 1)),
                          Genus = c(nrow(df4),sum(df4$taxprc > 0.01),sum(df4$taxprc > 0.1),sum(df4$taxprc > 1)),
                          ASV = c(nrow(df5),sum(df5$taxprc > 0.01),sum(df5$taxprc > 0.1),sum(df5$taxprc > 1)))

# Count of ASV and taxa in 151 samples
kable(df.count, row.names = F,digits = 1, caption = 'Abundance of phyla, family, genera and ASV in 151 samples')%>% 
  kable_classic(full_width = F, position = "left")%>%  
  kable_styling(latex_options = c("scale_down", "hold_position"))

# Se quiser exportar para um arquivo Excel
FileName <- paste(over_group_timepoint,"/Abundance of phyla, family, genera and ASV in 151 samples.xlsx", sep = "")
write_xlsx(df.count,FileName)

# Top 6 dominating phyla (prc abundance)
kable(head(df2[order(df2$taxprc,decreasing = T),c("Kingdom","Phylum","taxprc")]), row.names = F,digits = 1, caption = 'Average abundance according to phylum in 151 samples',col.names = c("Kingdom","Phylum","Abundance (%)"))%>% 
  kable_classic(full_width = F, position = "left")%>%  
  kable_styling(latex_options = c("scale_down", "hold_position"))

# Se quiser exportar para um arquivo Excel
FileName <- paste(over_group_timepoint,"/Average abundance according to phylum in 151 samples.xlsx", sep = "")
write_xlsx(df2,FileName)

# Top 6 dominating family (prc abundance)
kable(head(df3[order(df3$taxprc,decreasing = T),c("Kingdom","Phylum","Family", "taxprc")]), row.names = F,digits = 1, caption = 'Average abundance according to family in 151 samples',col.names = c("Kingdom","Phylum", "Family", "Abundance (%)"))%>% 
  kable_classic(full_width = F, position = "left")%>%  
  kable_styling(latex_options = c("scale_down", "hold_position"))

# Se quiser exportar para um arquivo Excel
FileName <- paste(over_group_timepoint,"/Average abundance according to family in 151 samples.xlsx", sep = "")
write_xlsx(df3,FileName)

# Top 6 dominating (genera prc abundance)
kable(head(df4[order(df4$taxprc,decreasing = T),c("Kingdom","Phylum","Class","Order","Family","Genus","taxprc")]), row.names = F,digits = 1, caption = 'Average abundance according to genus in 151 samples',col.names = c("Kingdom","Phylum","Class","Order","Family","Genus","Abundance (%)"))%>% 
  kable_classic(full_width = F, position = "left")%>%  
  kable_styling(latex_options = c("scale_down", "hold_position"))

# Se quiser exportar para um arquivo Excel
FileName <- paste(over_group_timepoint,"/Average abundance according to genus in 151 samples.xlsx", sep = "")
write_xlsx(df4,FileName)

# clean environment
rm(list = ls(all = TRUE))
```
\FloatBarrier

### 1.1.4 452 x 151 composition per Timepoint - Phylum level
```{r 452_beta_comp_Phylum, eval=T, echo=F}
path <- '/home/local.hcpa.ufrgs.br/olovison/Projects/Tasso_et_al_2025/Analysis'
over_Group_Timepoint = paste(path,"/overview_by_group_and_timepoint/",sep = "")

#Importando o objeto phyloseq aglomerado em gênero
ps <- readRDS("ps1.dna.phy.rds")

# Transformar abundâncias absolutas em abundâncias relativas
ps_ra <- transform_sample_counts(ps, function(x) x / sum(x))
ps_ra_melt <- psmelt(ps_ra)

#Definindo a paleta de cores para a variável principal
palette <- c("darkgreen", "magenta")

#Legend
g_legend<-function(a.gplot){ 
  tmp <- ggplot_gtable(ggplot_build(a.gplot)) 
  leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box") 
  legend <- tmp$grobs[[leg]] 
  return(legend)} 
mytheme <- theme(axis.title = element_text(size = 10), axis.text = element_text(size = 8)) + theme_bw()

# Subset
Phylum.summary <- aggregate(Abundance~Group+Phylum, data = ps_ra_melt, FUN = mean)
Phylum.summary.ordered <- Phylum.summary[order(Phylum.summary$Abundance,decreasing = T),]

# Encontrando top10 por Timepoint
Phylum.top.1 <- Phylum.summary.ordered$Phylum[Phylum.summary.ordered$Group == "452"][1:10]
Phylum.top.2 <- Phylum.summary.ordered$Phylum[Phylum.summary.ordered$Group == "151"][1:10]
#Phylum.top.3 <- Phylum.summary.ordered$Phylum[Phylum.summary.ordered$Timepoint == "Timepoint 3"][1:10]

# subset 
top10 <- unique(c(Phylum.top.1,Phylum.top.2))#,Phylum.top.3))
top10.max <- aggregate(Abundance~Phylum, data = Phylum.summary.ordered[Phylum.summary.ordered$Phylum %in% top10,], max)

Phylum.keep <- top10.max$Phylum[top10.max$Abundance>0.008]

# fig (Boxplot top Phylum por Group)
ps_ra_melt$Abundance_percent <- ifelse(ps_ra_melt$Abundance < 0.001, 0.1,ps_ra_melt$Abundance*100)

F1 <- ggplot(ps_ra_melt[ps_ra_melt$Phylum %in% Phylum.keep,], aes(y = Phylum, x = Abundance_percent)) + 
  geom_boxplot(position =position_dodge2(reverse = TRUE), aes(color = Group), alpha = 0.5) + 
  geom_boxplot(position =position_dodge2(reverse = TRUE), aes(fill = Group), alpha = 0.5, outlier.shape = 21) +
  facet_wrap(~ Timepoint, nrow = 1) +
  scale_fill_manual(values = palette) + 
  scale_color_manual(values = palette) + 
  scale_x_log10() +
  ylab("") +
  xlab("Abundance (%)") +
  theme_bw() + theme(axis.title = element_text(size = 10), axis.text.x = element_text(size = 8),legend.position = 'bottom',axis.text.y = element_text(face="italic",size = 8),
  plot.margin = unit(c(1, 1, 1, 1), "lines")) # Ajuste as margens aqui (topo, direita, baixo, esquerda)

print(F1)

# plot legend
F1_legend <- g_legend(F1 + geom_boxplot(aes(color=Group,fill=Group),alpha=0.5)+ 
  theme_bw() + theme(axis.title = element_text(size = 10), 
                     axis.text = element_text(size = 8), 
                     axis.text.x=element_blank(), 
                     axis.ticks.x=element_blank(), 
                     legend.position = 'bottom'))

#Salvando
FileName <- paste(over_Group_Timepoint,"/Top Phylum Abundance by Group and Timepoint.pdf", sep = "")
ggsave(FileName, plot = F1, width = 180, height = 170, units = "mm", dpi = 300)

#Salvando
FileName <- paste(over_Group_Timepoint,"/Top Phylum Abundance by Group and Timepoint.png", sep = "")
ggsave(FileName, plot = F1, width = 180, height = 170, units = "mm", dpi = 300)

# Se quiser exportar para um arquivo Excel
FileName <- paste(over_Group_Timepoint,"/Top Phylum Abundance by Group and Timepoint.xlsx", sep = "")
write_xlsx(ps_ra_melt, FileName)

# clean environment
rm(list = ls(all = TRUE))
```
\FloatBarrier

### 1.1.5 452 x 151 composition per Timepoint - Family level
```{r 452_dis_comp_family, eval=T, echo=F}
path <- '/home/local.hcpa.ufrgs.br/olovison/Projects/Tasso_et_al_2025/Analysis'
over_Group_Timepoint = paste(path,"/overview_by_group_and_timepoint/",sep = "")

#Importando o objeto phyloseq aglomerado em gênero
ps <- readRDS("ps1.dna.family.rds")

# Transformar abundâncias absolutas em abundâncias relativas
ps_ra <- transform_sample_counts(ps, function(x) x / sum(x))
ps_ra_melt <- psmelt(ps_ra)

#Definindo a paleta de cores para a variável principal
palette <- c("darkgreen", "magenta")

#Legend
g_legend<-function(a.gplot){ 
  tmp <- ggplot_gtable(ggplot_build(a.gplot)) 
  leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box") 
  legend <- tmp$grobs[[leg]] 
  return(legend)} 
mytheme <- theme(axis.title = element_text(size = 10), axis.text = element_text(size = 8)) + theme_bw()

# Subset
family.summary <- aggregate(Abundance~Group+Family, data = ps_ra_melt, FUN = mean)
family.summary.ordered <- family.summary[order(family.summary$Abundance,decreasing = T),]

# Encontrando top10 por Timepoint
family.top.1 <- family.summary.ordered$Family[family.summary.ordered$Group == "452"][1:10]
family.top.2 <- family.summary.ordered$Family[family.summary.ordered$Group == "151"][1:10]
#family.top.3 <- family.summary.ordered$Family[family.summary.ordered$Timepoint == "Timepoint 3"][1:10]

# subset 
top10 <- unique(c(family.top.1,family.top.2))#,family.top.3))
top10.max <- aggregate(Abundance~Family, data = family.summary.ordered[family.summary.ordered$Family %in% top10,], max)

family.keep <- top10.max$Family[top10.max$Abundance>0.03]

# fig 3a (Boxplot top family por Timepoint)
ps_ra_melt$Abundance_percent <- ifelse(ps_ra_melt$Abundance < 0.001, 0.1,ps_ra_melt$Abundance*100)

F2 <- ggplot(ps_ra_melt[ps_ra_melt$Family %in% family.keep,], aes(y = Family, x = Abundance_percent)) + 
  geom_boxplot(position =position_dodge2(reverse = TRUE), aes(color = Group), alpha = 0.5) + 
  geom_boxplot(position =position_dodge2(reverse = TRUE), aes(fill = Group), alpha = 0.5, outlier.shape = 21) +
  facet_wrap(~ Timepoint, nrow = 1) +
  scale_fill_manual(values = palette) + 
  scale_color_manual(values = palette) + 
  scale_x_log10() +
  ylab("") +
  xlab("Abundance (%)") +
  theme_bw() + theme(axis.title = element_text(size = 10), axis.text.x = element_text(size = 8),legend.position = 'bottom',axis.text.y = element_text(face="italic",size = 8),
  plot.margin = unit(c(1, 1, 1, 1), "lines")) # Ajuste as margens aqui (topo, direita, baixo, esquerda)

print(F2)

# plot legend
F2_legend <- g_legend(F2 + geom_boxplot(aes(color=Group,fill=Group),alpha=0.5)+ 
  theme_bw() + theme(axis.title = element_text(size = 10), 
                     axis.text = element_text(size = 8), 
                     axis.text.x=element_blank(), 
                     axis.ticks.x=element_blank(), 
                     legend.position = 'bottom'))

#Salvando
FileName <- paste(over_Group_Timepoint,"/Top family Abundance by Group and Timepoint.pdf", sep = "")
ggsave(FileName, plot = F2, width = 180, height = 170, units = "mm", dpi = 300)

#Salvando
FileName <- paste(over_Group_Timepoint,"/Top family Abundance by Group and Timepoint.png", sep = "")
ggsave(FileName, plot = F2, width = 180, height = 170, units = "mm", dpi = 300)

# Se quiser exportar para um arquivo Excel
FileName <- paste(over_Group_Timepoint,"/Top family Abundance by Group and Timepoint.xlsx", sep = "")
write_xlsx(ps_ra_melt, FileName)

# clean environment
rm(list = ls(all = TRUE))
```
\FloatBarrier

### 1.1.6 452 x 151 composition per Timepoint - Genus level
```{r 452_dis_comp_genus, eval=T, echo=F}
path <- '/home/local.hcpa.ufrgs.br/olovison/Projects/Tasso_et_al_2025/Analysis'
over_Group_Timepoint = paste(path,"/overview_by_group_and_timepoint/",sep = "")

#Importando o objeto phyloseq aglomerado em gênero
ps <- readRDS("ps1.dna.genus.rds")

# Transformar abundâncias absolutas em abundâncias relativas
ps_ra <- transform_sample_counts(ps, function(x) x / sum(x))
ps_ra_melt <- psmelt(ps_ra)

#Definindo a paleta de cores para a variável principal
palette <- c("darkgreen", "magenta")

#Legend
g_legend<-function(a.gplot){ 
  tmp <- ggplot_gtable(ggplot_build(a.gplot)) 
  leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box") 
  legend <- tmp$grobs[[leg]] 
  return(legend)} 
mytheme <- theme(axis.title = element_text(size = 10), axis.text = element_text(size = 8)) + theme_bw()

# subset relevant taxa
genus.summary <- aggregate(Abundance~Group+Genus, data = ps_ra_melt, FUN = mean)
genus.summary.ordered <- genus.summary[order(genus.summary$Abundance,decreasing = T),]

# find top 10 per time point
genus.top.1 <- genus.summary.ordered$Genus[genus.summary.ordered$Group == "452"][1:10]
genus.top.2 <- genus.summary.ordered$Genus[genus.summary.ordered$Group == "151"][1:10]
#genus.top.3 <- genus.summary.ordered$Genus[genus.summary.ordered$Timepoint == "Timepoint 3"][1:10]

# subset the ones with mead abundance above 
top10 <- unique(c(genus.top.1,genus.top.2))#,genus.top.3))
top10.max <- aggregate(Abundance~Genus, data = genus.summary.ordered[genus.summary.ordered$Genus %in% top10,], max)


genus.keep <- top10.max$Genus[top10.max$Abundance>0.03]


# fig 2 a (boxplot top genera by timepint)
ps_ra_melt$Abundance_percent <- ifelse(ps_ra_melt$Abundance < 0.001, 0.1,ps_ra_melt$Abundance*100)

F3 <- ggplot(ps_ra_melt[ps_ra_melt$Genus %in% genus.keep,], aes(y = Genus, x = Abundance_percent)) + 
  geom_boxplot(position =position_dodge2(reverse = TRUE), aes(color = Group), alpha = 0.5) + 
  geom_boxplot(position =position_dodge2(reverse = TRUE), aes(fill = Group), alpha = 0.5, outlier.shape = 21) +
  facet_wrap(~ Timepoint, nrow = 1) +
  scale_fill_manual(values = palette) + 
  scale_color_manual(values = palette) + 
  scale_x_log10() +
  ylab("") +
  xlab("Abundance (%)") +
  theme_bw() + theme(axis.title = element_text(size = 10), axis.text.x = element_text(size = 8),legend.position = 'bottom',axis.text.y = element_text(face="italic",size = 8),
  plot.margin = unit(c(1, 1, 1, 1), "lines")) # Ajuste as margens aqui (topo, direita, baixo, esquerda)

print(F3)

# plot legend
F3_legend <- g_legend(F3 + geom_boxplot(aes(color=Group,fill=Group),alpha=0.5)+ 
  theme_bw() + theme(axis.title = element_text(size = 10), 
                     axis.text = element_text(size = 8), 
                     axis.text.x=element_blank(), 
                     axis.ticks.x=element_blank(), 
                     legend.position = 'bottom'))

#Salvando
FileName <- paste(over_Group_Timepoint,"/Top Genera Abundance by Group and Timepoint.pdf", sep = "")
ggsave(FileName, plot = F3, width = 180, height = 170, units = "mm", dpi = 300)

#Salvando
FileName <- paste(over_Group_Timepoint,"/Top Genera Abundance by Group and Timepoint.png", sep = "")
ggsave(FileName, plot = F3, width = 180, height = 170, units = "mm", dpi = 300)

# Se quiser exportar para um arquivo Excel
FileName <- paste(over_Group_Timepoint,"/Top Genera Abundance by Group and Timepoint.xlsx", sep = "")
write_xlsx(ps_ra_melt, FileName)

# clean environment
rm(list = ls(all = TRUE))
```
\FloatBarrier

# 2.0 Alpha diversity
## 2.1 Boxplot
```{r alpha_boxplot, message=FALSE, warning=FALSE, echo=FALSE, fig.align='center', fig.width=6, fig.height=4, fig.cap='Mean Shannon diversity over Days since start by Group\n(Mean ± SE; ***/**/* indicates p<0.01/0.05/0.1)'}
# --- 1) Pacotes necessários ---
library(phyloseq)
library(nlme)
library(dplyr)
library(ggplot2)
library(ggpubr)
library(broom)
library(tidyr)

# --- 2) Diretório e dados ---
path      <- '/home/local.hcpa.ufrgs.br/olovison/Projects/Tasso_et_al_2025/Analysis'
alpha_div <- file.path(path, "alpha_div")
if (!dir.exists(alpha_div)) dir.create(alpha_div, recursive = TRUE)

ps      <- readRDS("ps1.dna.rds")
df.adiv <- cbind(
  data.frame(sample_data(ps)),
  estimate_richness(ps, measures = "Shannon")
) %>%
  mutate(
    Timepoint = factor(Timepoint, levels = c("Timepoint1","Timepoint2")),
    Group      = factor(Group)
  )

# --- 3) Ajuste do modelo misto (Days_since_start contínuo) ---
df_clean <- df.adiv %>%
  select(
    Shannon, Days_since_start, Group, Sex, Age,
    BMI_classification, HbA1C, Hypertension,
    Dyslipidemia, Hypothyroidism,
    Antibiotic_use_.in_the_past_6_months.,
    Alcohol_consumption, PatientID
  ) %>%
  drop_na()  # garante casos completos

df_clean$BMI_classification <- factor(df_clean$BMI_classification, levels = c("normal weight", "overweight", "obesity"))
df_clean$Antibiotic_use_.in_the_past_6_months. <- factor(df_clean$Antibiotic_use_.in_the_past_6_months., levels = c("no", "yes"))
df_clean$Alcohol_consumption <- factor(df_clean$Alcohol_consumption, levels = c("no", "yes"))


model_shannon <- lme(
  fixed       = Shannon ~ Days_since_start * Group +
                  Sex + Age + BMI_classification + HbA1C +
                  Hypertension + Dyslipidemia + Hypothyroidism +
                  Antibiotic_use_.in_the_past_6_months. +
                  Alcohol_consumption,
  random      = ~ 1 | PatientID,
  data        = df_clean,
  method      = "REML",
  na.action   = na.omit,
  control     = lmeControl(maxIter = 100, msMaxIter = 100, opt = "optim")
)

# --- 4) Cálculo de p-values por Timepoint (t-test simples) ---
group_lvls <- levels(df.adiv$Group)  # ex: c("Control","Treatment")

pvals_tp <- df.adiv %>%
  filter(!is.na(Shannon)) %>%
  group_by(Timepoint) %>%
  summarise(
    p.value = t.test(Shannon ~ Group, data = cur_data())$p.value,
    y_max   = max(Shannon, na.rm = TRUE)
  ) %>%
  ungroup() %>%
  mutate(
    y.position = y_max + 0.1,
    label      = case_when(
      p.value < 0.01 ~ "***",
      p.value < 0.05 ~ "**",
      p.value < 0.1  ~ "*",
      TRUE           ~ NA_character_
    ),
    group1 = group_lvls[1],
    group2 = group_lvls[2]
  ) %>%
  filter(!is.na(label))

# --- 5) Construção do boxplot facetado por Timepoint ---
F_box <- ggplot(df.adiv, aes(Group, Shannon, color = Group, fill = Group)) +
  geom_boxplot(outlier.shape = NA) +
  stat_summary(fun = median, geom = "crossbar", width = 0.6,
               fatten = 2, color = "black") +
  scale_color_manual(values = c("darkgreen","magenta")) +
  scale_fill_manual(values  = c("darkgreen","magenta")) +
  facet_wrap(~ Timepoint, nrow = 1) +
  labs(
    y       = "Shannon diversity index",
    x       = NULL,
    caption = "* p < 0.1; ** p < 0.05; *** p < 0.01"
  ) +
  theme_bw(base_size = 11) +
  theme(
    legend.position  = "bottom",
    axis.text.x      = element_blank(),
    axis.ticks.x     = element_blank(),
    plot.caption     = element_text(size = 9, hjust = 0.5, face = "italic")
  ) +
  stat_pvalue_manual(
    data        = pvals_tp,
    mapping     = aes(group1 = group1,
                      group2 = group2,
                      y.position = y.position,
                      label = label),
    inherit.aes = FALSE,
    tip.length  = 0.02
  )

print(F_box)

# --- 6) Salvando a figura ---
ggsave(
  file.path(alpha_div, "shannon_boxplot.pdf"),
  plot   = F_box,
  width  = 6, height = 4, units = "in", dpi = 300
)

ggsave(
  file.path(alpha_div, "shannon_boxplot.png"),
  plot   = F_box,
  width  = 6, height = 4, units = "in", dpi = 300
)
```
Shannon diversity indices were calculated from 16S rRNA gene sequencing data using the phyloseq R package. The data set was processed to include only complete cases for the variables of interest, which comprised Shannon diversity, days since study start, intervention group, sex, age, BMI classification, HbA1C, hypertension, dyslipidemia, hypothyroidism, recent antibiotic use, alcohol consumption, and patient ID.

A linear mixed-effects model was fitted to assess the association between Shannon diversity and days since study start (as a continuous variable), with fixed effects for group, sex, age, BMI classification, HbA1C, hypertension, dyslipidemia, hypothyroidism, recent antibiotic use, and alcohol consumption. Patient ID was included as a random effect to account for repeated measures. Model estimation was performed using restricted maximum likelihood (REML) via the nlme package.

For visualization, boxplots of Shannon diversity were generated for each group and timepoint using ggplot2, with additional summary statistics (median bars) and custom coloring. Group comparisons at each timepoint were performed using unpaired t-tests, and resulting p-values were annotated on the plots with standard significance codes (*p<0.1, **p<0.05, ***p<0.01). 
\FloatBarrier

## 2.2 Alpha diversity lineplot
```{r alpha_lineplot, message=FALSE, warning=FALSE, echo=FALSE,fig.align='center', fig.width=8, fig.height=6,fig.cap='Mean Shannon diversity over Timepoint by Group\n(Mean ± SE; interaction details)\n* p < 0.1; ** p < 0.05; *** p < 0.01; ns = not significant'}
set.seed(123)

# --- 1) Pacotes necessários ---
library(phyloseq)
library(nlme)
library(dplyr)
library(ggplot2)
library(tidyr)

# --- 2) Diretórios e dados ---
path      <- '/home/local.hcpa.ufrgs.br/olovison/Projects/Tasso_et_al_2025/Analysis'
alpha_div <- file.path(path, "alpha_div")
if (!dir.exists(alpha_div)) dir.create(alpha_div, recursive = TRUE)

ps      <- readRDS("ps1.dna.rds")
df.adiv <- sample_data(ps) %>% 
  as("data.frame") %>%
  mutate(
    Timepoint        = factor(Timepoint, levels = c("Timepoint1","Timepoint2")),
    Days_since_start = as.numeric(Days_since_start),
    Group            = factor(Group),
  ) %>%
  bind_cols( estimate_richness(ps, measures = "Shannon") ) %>%
  drop_na(Timepoint, Days_since_start, Shannon, Group)

# --- 3) Sumário por Timepoint & Group (mean ± SE) ---
df_sum <- df.adiv %>%
  group_by(Timepoint, Group) %>%
  summarise(
    meanShannon = mean(Shannon),
    seShannon   = sd(Shannon) / sqrt(n()),
    .groups     = "drop"
  )

# --- 4) Modelo misto usando Days_since_start contínuo ---
df_clean <- df.adiv %>%
  select(
    Shannon, Days_since_start, Group, Sex, 
    BMI_classification, HbA1C,
    Hypertension, Dyslipidemia, Hypothyroidism,
    Antibiotic_use_.in_the_past_6_months., Alcohol_consumption,
    PatientID
  ) %>%
  drop_na()

df_clean$BMI_classification <- factor(df_clean$BMI_classification, levels = c("normal weight", "overweight", "obesity"))
df_clean$Antibiotic_use_.in_the_past_6_months. <- factor(df_clean$Antibiotic_use_.in_the_past_6_months., levels = c("no", "yes"))
df_clean$Alcohol_consumption <- factor(df_clean$Alcohol_consumption, levels = c("no", "yes"))

model_shannon <- lme(
  fixed       = Shannon ~ Days_since_start * Group +
                  Sex + BMI_classification + HbA1C +
                  Hypertension + Dyslipidemia + Hypothyroidism +
                  Antibiotic_use_.in_the_past_6_months. +
                  Alcohol_consumption,
  random      = ~ 1 | PatientID,
  data        = df_clean,
  method      = "REML",
  na.action   = na.omit,
  control     = lmeControl(maxIter = 100, msMaxIter = 100, opt = "optim")
)

# --- 5) Teste t em cada Timepoint para figura ---
pvals_tp <- df.adiv %>%
  group_by(Timepoint) %>%
  summarise(
    p.value = t.test(Shannon ~ Group, data = cur_data())$p.value,
    y_max   = max(Shannon, na.rm = TRUE),
    .groups = "drop"
  ) %>%
  mutate(
    y.position = y_max + 0.1,
    label      = case_when(
      p.value < 0.01 ~ "***",
      p.value < 0.05 ~ "**",
      p.value < 0.10 ~ "*",
      TRUE           ~ NA_character_
    )
  ) %>%
  filter(!is.na(label))

# --- 6) Monta o line-plot com errorbars e textos de p-valor ---
palette <- c("darkgreen","magenta")
F_line <- ggplot(df_sum, aes(x = Timepoint, y = meanShannon, color = Group, group = Group)) +
  geom_line(size = 1) +
  geom_point(size = 3) +
  geom_errorbar(aes(ymin = meanShannon - seShannon,
                    ymax = meanShannon + seShannon),
                width = 0.1) +
  scale_color_manual(values = palette, name = "Group") +
  labs(
    title    = "Mean Shannon Diversity over Timepoint by Group",
    subtitle = sprintf(
      "Interaction p = %.3g",
      summary(model_shannon)$tTable[
        paste0("Days_since_start:Group", levels(df.adiv$Group)[2]), "p-value"
      ]
    ),
    x       = "Timepoint",
    y       = "Mean Shannon ± SE",
    caption = "* p < 0.1; ** p < 0.05; *** p < 0.01"
  ) +
  theme_bw(base_size = 11) +
  theme(
    legend.position = "bottom",
    plot.title      = element_text(hjust = 0.5),
    plot.subtitle   = element_text(hjust = 0.5),
    plot.caption    = element_text(size = 9, hjust = 0.5, face = "italic")
  ) +
  # adiciona os asteriscos acima de cada categoria, sem linhas de bracket
  geom_text(
    data          = pvals_tp,
    aes(x = Timepoint, y = y.position, label = label),
    inherit.aes   = FALSE,
    size          = 5,
    vjust         = 0
  )

print(F_line)

# --- 7) Salva figura ---
ggsave(
  filename = file.path(alpha_div, "shannon_lineplot.pdf"),
  plot     = F_line,
  width    = 8, height = 6, units = "in", dpi = 300
)
ggsave(
  filename = file.path(alpha_div, "shannon_lineplot.png"),
  plot     = F_line,
  width    = 8, height = 6, units = "in", dpi = 300
)
```
Shannon diversity indices were calculated using 16S rRNA gene sequencing data processed with the phyloseq R package. Only samples with complete data for all relevant variables were included. The dataset comprised Shannon diversity, days since study start, group allocation, sex, BMI classification, HbA1C, hypertension, dyslipidemia, hypothyroidism, recent antibiotic use, alcohol consumption, and patient ID.

Summary statistics (mean ± standard error) of Shannon diversity were computed by group and timepoint. To assess the longitudinal effect of time and group, a linear mixed-effects model was fitted using the nlme package. The model included days since study start, group, and their interaction as fixed effects, as well as additional covariates (sex, BMI classification, HbA1C, hypertension, dyslipidemia, hypothyroidism, recent antibiotic use, and alcohol consumption). Patient ID was included as a random effect to account for repeated measures. Model estimation used restricted maximum likelihood (REML).

For visualization, mean Shannon diversity values (± SE) were plotted by group across timepoints using line plots with error bars (ggplot2). Group comparisons at each timepoint were evaluated by unpaired t-tests, with p-values annotated on the plots using standard significance codes (*p<0.1, **p<0.05, ***p<0.01). The interaction p-value from the mixed-effects model was displayed in the plot subtitle to indicate whether temporal trends differed between groups. 

\FloatBarrier
## 2.3 Alpha diversity mixed effects linear model
```{r alpha_b,eval=TRUE, echo=F}
set.seed(123)
library(nlme)
library(dplyr)
library(tibble)
library(knitr)
library(kableExtra)
library(writexl)

# 1. Extrair tabela de efeitos fixos e IC (apenas "fixed")
sm <- summary(model_shannon)$tTable
ci <- intervals(model_shannon, level = 0.95, which = "fixed")$fixed

tbl_shannon <- sm %>%
  as.data.frame() %>%
  rownames_to_column(var = "term") %>%
  rename(
    Estimate     = Value,
    `Std. Error` = Std.Error,
    DF           = DF,
    t.value      = `t-value`,
    `p-value`    = `p-value`
  ) %>%
  mutate(
    `CI Lower` = ci[term, "lower"],
    `CI Upper` = ci[term, "upper"]
  )

tbl_shannon

# Se quiser exportar para um arquivo Excel
FileName <- paste(alpha_div,"/Shannon model.xlsx", sep = "")
write_xlsx(tbl_shannon, FileName)

# 2. Formatar em kable
tbl_shannon %>%
  select(term, Estimate, `Std. Error`, DF, t.value, `p-value`, `CI Lower`, `CI Upper`) %>%
  kable(
    caption  = "Fixed effects of the mixed-effects model for Shannon.",
    digits   = 3,
    booktabs = TRUE
  ) %>%
  kable_styling(
    full_width    = FALSE,
    position      = "center",
    latex_options = c("scale_down", "hold_position")
  ) %>%
  footnote(
    general       = "LME model with a continuous-time structure for PatientID/group.",
    general_title = ""
  )

# clean environment
rm(list = ls(all = TRUE))
```
Key Fixed Effects

Days_since_start:
Estimate: 0.0018, p-value: 0.18

Each additional day since the start is associated with a small, non-significant increase in Shannon diversity.

Group452:
Estimate: –0.29, p-value: 0.24

Group 452 has a lower Shannon diversity compared to the reference group, but this difference is not significant.

Sexmale:
Estimate: –0.18, p-value: 0.48

Males have slightly lower Shannon diversity than females, but the difference is not significant.

BMI_classificationoverweight:
Estimate: 0.45, p-value: 0.095

Individuals classified as overweight have higher Shannon diversity compared to normal weight, with the difference being marginally significant (p ≈ 0.095, 95% CI: –0.089 to 0.997). Suggestive of a possible positive effect, but not conventionally significant.

BMI_classificationobesity:
Estimate: 0.24, p-value: 0.35

Obese individuals have a slightly higher Shannon diversity than normal weight, but this is not significant.

HbA1C:
Estimate: –0.040, p-value: 0.55

No evidence of a significant association between HbA1C and Shannon diversity.

Hypertensionyes:
Estimate: –0.022, p-value: 0.93

No effect; not significant.

Dyslipidemiayes:
Estimate: 0.23, p-value: 0.38

No significant difference.

Hypothyroidismyes:
Estimate: 0.42, p-value: 0.33

No significant difference.

Days_since_start:Group452
Estimate: –0.00403
Standard Error: 0.00179
t-value: –2.25
p-value: 0.041
95% CI: –0.00787 to –0.00019

Interpretation
This interaction term assesses whether the rate of change in Shannon diversity over time (days since start) differs between Group 452 and the reference group.

The negative and statistically significant estimate (p = 0.041) indicates that, in Group 452, the Shannon diversity index changes at a significantly slower rate (or possibly declines) over time compared to the reference group, after adjusting for all other variables in the model.

In practical terms:
For each additional day since the start, Group 452 shows a decrease in Shannon diversity relative to the reference group, and this effect is unlikely to be due to random chance.
\FloatBarrier

### 2.3.1 Checking residuals normality
```{r alpha_c,eval=TRUE, echo=F}
#Obter os resíduos do modelo
residuals <- residuals(model_shannon)

# Teste de Shapiro-Wilk para normalidade dos resíduos
shapiro.test(residuals)

# O valor p retornado pelo teste indica se os resíduos seguem uma distribuição normal. Se o valor p for maior que 0.05, você não rejeita a hipótese nula de que os resíduos são normalmente distribuídos, o que é bom para o modelo. Se o valor p for menor que 0.05, os resíduos não seguem uma distribuição normal, o que pode ser um problema e pode exigir transformações nos dados (logarítmica, raíz quadrada ou Box-Cox) ou o uso de modelos não paraḿetricos como Modelos aditivos generalizados (GAMs), Modelos de Regressão Robusta ou Modelos de Regressão Generalizados (GLMMs).
```
The normality of the residuals validate the model adjustment.
\FloatBarrier

# 3.0 Beta diversity and Clustering - Cross Sectional and Time Series
```{r beta_div_a_ellipses, eval=TRUE, echo=FALSE, message=FALSE, warning=FALSE, results='asis'}
# --- 0) Libraries ---
library(phyloseq)
library(compositions)
library(vegan)
library(ape)
library(ggplot2)
library(dplyr)
library(tibble)
library(writexl)
library(microbiome)

# --- 1) Palette & shapes for Group ---
palette <- c("452" = "darkgreen", "151" = "magenta")
shapes  <- c("452" = 21, "151" = 22)

# --- 2) Paths ---
path       <- '/home/local.hcpa.ufrgs.br/olovison/Projects/Tasso_et_al_2025/Analysis'
Clustering <- file.path(path, "Clustering")
dir.create(Clustering, showWarnings = FALSE, recursive = TRUE)

# --- 3) Load phyloseq object ---
ps <- readRDS("ps1.dna.rds")

# --- 4) Function to subset phyloseq by timepoint robustly ---
phy_timepoint <- function(ps, tp_value) {
  meta <- as(sample_data(ps), "data.frame")
  keep_samples <- rownames(meta)[as.character(meta$Timepoint) == tp_value]
  ps_sub <- prune_samples(keep_samples, ps)
  ps_sub <- prune_taxa(taxa_sums(ps_sub) > 0, ps_sub)
  return(ps_sub)
}

ps_tp1 <- phy_timepoint(ps, "Timepoint1")
ps_tp2 <- phy_timepoint(ps, "Timepoint2")

# --- 5) Function for beta diversity analysis and plotting ---
run_beta_div <- function(ps_sub, tp) {
  meta_sub <- sample_data(ps_sub) %>%
    as("data.frame") %>%
    mutate(Group = factor(Group, levels = names(palette)))
  seq_counts <- as.data.frame(otu_table(ps_sub)) # amostras já em linhas!
  
  # Checagem de consistência
  stopifnot(nrow(seq_counts) == nrow(meta_sub))
  
  # --- ILR-PCA ---
  ilr_ratios <- compositions::ilr(as.matrix(seq_counts))
  pca_res    <- prcomp(ilr_ratios, scale. = FALSE)
  pca_vars   <- pca_res$sdev^2 / sum(pca_res$sdev^2)
  df_pca     <- data.frame(
    PC1 = pca_res$x[,1],
    PC2 = pca_res$x[,2],
    meta_sub
  )
  p_pca <- ggplot(df_pca, aes(PC1, PC2, fill = Group, shape = Group)) +
    stat_ellipse(aes(color = Group), geom = "path", size = 1, level = 0.95) +
    geom_point(size = 3, color = "black", alpha = 0.85) +
    scale_color_manual(values = palette) +
    scale_fill_manual(values = palette) +
    scale_shape_manual(values = shapes) +
    labs(
      title = paste0("ILR-PCA – ", tp),
      x     = paste0("PC1 (", round(pca_vars[1]*100,1), "%)"),
      y     = paste0("PC2 (", round(pca_vars[2]*100,1), "%)")
    ) +
    theme_bw(base_size = 12) +
    theme(legend.position = "bottom")
  print(p_pca)
  ggsave(file.path(Clustering, paste0("ILR_PCA_", tp, ".pdf")), p_pca)
  write_xlsx(df_pca, file.path(Clustering, paste0("ILR_PCA_scores_", tp, ".xlsx")))
  
  # --- PCoA Jaccard ---
  jac_dmat <- vegdist(seq_counts, method = "jaccard")
  pcoa_jac <- ape::pcoa(jac_dmat)
  jac_vars <- pcoa_jac$values$Relative_eig
  df_pcoa  <- data.frame(
    Axis.1 = pcoa_jac$vectors[,1],
    Axis.2 = pcoa_jac$vectors[,2],
    meta_sub
  )
  p_pcoa <- ggplot(df_pcoa, aes(Axis.1, Axis.2, fill = Group, shape = Group)) +
    stat_ellipse(aes(color = Group), geom = "path", size = 1, level = 0.95) +
    geom_point(size = 3, color = "black", alpha = 0.85) +
    scale_color_manual(values = palette) +
    scale_fill_manual(values = palette) +
    scale_shape_manual(values = shapes) +
    labs(
      title = paste0("PCoA (Jaccard) – ", tp),
      x     = paste0("Axis 1 (", round(jac_vars[1]*100,1), "%)"),
      y     = paste0("Axis 2 (", round(jac_vars[2]*100,1), "%)")
    ) +
    theme_bw(base_size = 12) +
    theme(legend.position = "bottom")
  print(p_pcoa)
  ggsave(file.path(Clustering, paste0("PCoA_Jaccard_", tp, ".pdf")), p_pcoa)
  write_xlsx(df_pcoa, file.path(Clustering, paste0("PCoA_Jaccard_scores_", tp, ".xlsx")))
}

# --- 6) Run for each timepoint ---
run_beta_div(ps_tp1, "Timepoint1")
run_beta_div(ps_tp2, "Timepoint2")

```
\FloatBarrier

## 3.1 Beta diversity statistical analysis
### 3.1.1 Beta dispersion
```{r beta_disp, eval=T, echo=F}
# --- Beta-dispersão por timepoint: Aitchison e Jaccard ---

library(vegan)
library(tibble)
library(knitr)
library(kableExtra)
library(writexl)
library(compositions)

# Função para rodar beta dispersão e gerar outputs bonitos
run_beta_disp <- function(ps_sub, tp) {
  meta_sub <- sample_data(ps_sub) %>% as("data.frame")
  seq_counts <- as.data.frame(otu_table(ps_sub))
  
  # --- Aitchison (ILR + Euclidiana) ---
  ilr_mat <- compositions::ilr(as.matrix(seq_counts))
  euc_dist <- dist(ilr_mat)
  bd_ait <- betadisper(euc_dist, meta_sub$Group)
  disp_ait <- anova(bd_ait)
  
  # --- Jaccard ---
  jac_dist <- vegdist(seq_counts, method = "jaccard")
  bd_jac <- betadisper(jac_dist, meta_sub$Group)
  disp_jac <- anova(bd_jac)
  
  # --- Organiza resultados ---
  disp_table <- tibble(
    Distance = c("Aitchison", "Jaccard"),
    F.value  = c(disp_ait$`F value`[1],  disp_jac$`F value`[1]),
    P.value  = c(disp_ait$`Pr(>F)`[1],   disp_jac$`Pr(>F)`[1])
  )
  print(disp_table) # para inspeção interativa
  
  disp_table %>%
    kable(
      digits  = 3,
      caption = paste0("Test for homogeneity of dispersion (betadisper) – ", tp)
    ) %>%
    kable_styling(latex_options = c("hold_position", "scale_down"))
  
  # Exporta tabela em Excel (opcional)
  write_xlsx(disp_table, file.path(Clustering, paste0("beta_disp_", tp, ".xlsx")))
}

# --- Rodar para cada timepoint ---
run_beta_disp(ps_tp1, "Timepoint1")
run_beta_disp(ps_tp2, "Timepoint2")
```
Interpretation:

Timepoint 1

Aitchison and Jaccard: There was no statistically significant difference in dispersion between the sample groups at Timepoint 1.

Both p-values (0.225 and 0.244) are well above the standard threshold for significance (p < 0.05).

Conclusion: The groups showed similar within-group variability (i.e., homogeneity of multivariate dispersion) at this timepoint.

Interpretation:

Aitchison: No significant difference in dispersion (p = 0.496).

Jaccard: Significant difference in dispersion between groups (p = 0.0149).

The relatively high F-value and low p-value for Jaccard indicate that, at Timepoint 2, the groups differed significantly in their internal variability according to the Jaccard metric.

In other words, after treatment/intervention, one group became more heterogeneous in terms of presence/absence of ASVs than the other (according to Jaccard), but this was not detected using the Aitchison metric.

Summary for reporting
At Timepoint 1, there was no evidence of difference in dispersion between groups for either distance metric.

At Timepoint 2, only the Jaccard metric revealed significantly different dispersions between groups, suggesting that, after the intervention, the groups varied more in terms of presence/absence of taxa.

Note: When using PERMANOVA, significant differences in group dispersions can potentially influence the interpretation of group separation, as PERMANOVA is sensitive to both centroid and dispersion effects.

### 3.1.2 PERMANOVA - Timepoint 1
```{r beta_permanova, eval=T, echo=F}
# --- PERMANOVA (Timepoint 1) ---

library(vegan)
library(compositions)
library(broom)
library(knitr)
library(kableExtra)

# Metadados e matriz de contagens
meta_tp1 <- sample_data(ps_tp1) %>% as("data.frame")
seq_tp1  <- as.data.frame(otu_table(ps_tp1))

# --- Aitchison (ILR + Euclidiana) ---
ilr_mat1 <- compositions::ilr(as.matrix(seq_tp1))
dist_ait1 <- dist(ilr_mat1)
perm_ait1 <- adonis2(dist_ait1 ~ Group, data = meta_tp1, permutations = 999)

# --- Jaccard ---
dist_jac1 <- vegdist(seq_tp1, method = "jaccard")
perm_jac1 <- adonis2(dist_jac1 ~ Group, data = meta_tp1, permutations = 999)

# --- Tabelas para knit/report ---
broom::tidy(perm_ait1) %>%
  kable(
    digits = 3,
    caption = "PERMANOVA (Aitchison distance) – Group – Timepoint 1"
  ) %>%
  kable_styling(latex_options = "hold_position")

broom::tidy(perm_jac1) %>%
  kable(
    digits = 3,
    caption = "PERMANOVA (Jaccard distance) – Group – Timepoint 1"
  ) %>%
  kable_styling(latex_options = "hold_position")

# (Opcional) Print bruto para inspeção interativa
print(perm_ait1)
print(perm_jac1)
```

### 3.1.3 PERMANOVA - Timepoint 2
```{r beta_perm2, eval=T, echo=F}
# --- PERMANOVA Aitchison (Timepoint 2) ---

library(vegan)
library(compositions)
library(broom)
library(knitr)
library(kableExtra)

# Metadados e matriz de contagens
meta_tp2 <- sample_data(ps_tp2) %>% as("data.frame")
seq_tp2  <- as.data.frame(otu_table(ps_tp2))

# --- Aitchison (ILR + Euclidiana) ---
ilr_mat2  <- compositions::ilr(as.matrix(seq_tp2))
dist_ait2 <- dist(ilr_mat2)
perm_ait2 <- adonis2(dist_ait2 ~ Group, data = meta_tp2, permutations = 999)

# --- Tabela para knit/report ---
broom::tidy(perm_ait2) %>%
  kable(
    digits = 3,
    caption = "PERMANOVA (Aitchison distance) – Group – Timepoint 2"
  ) %>%
  kable_styling(latex_options = "hold_position")

# (Opcional) Print bruto para inspeção interativa
print(perm_ait2)

```


### 3.1.3 ANOSIM/MRPP - Timepoint 2
```{r beta_anosim_mrpp, eval=T, echo=F}
# --- ANOSIM e MRPP (Jaccard, Timepoint 2) ---

library(vegan)
library(knitr)
library(kableExtra)
library(tibble)

# Metadados e matriz de contagens
meta_tp2 <- sample_data(ps_tp2) %>% as("data.frame")
seq_tp2  <- as.data.frame(otu_table(ps_tp2))

# --- Jaccard distance ---
jac_dist2 <- vegdist(seq_tp2, method = "jaccard")

# --- ANOSIM ---
anosim2 <- anosim(jac_dist2, grouping = meta_tp2$Group, permutations = 999)

# --- MRPP ---
mrpp2 <- mrpp(jac_dist2, grouping = meta_tp2$Group, permutations = 999)

# --- Tabelas para knit/report ---
tibble(
  Method  = "ANOSIM (Jaccard)",
  R.stat  = anosim2$statistic,
  P.value = anosim2$signif
) %>%
  kable(
    digits = 3,
    caption = "ANOSIM (Jaccard) – Group – Timepoint 2"
  ) %>%
  kable_styling(latex_options = "hold_position")

tibble(
  Method  = "MRPP (Jaccard)",
  A.stat  = mrpp2$A,
  P.value = mrpp2$Pvalue
) %>%
  kable(
    digits = 3,
    caption = "MRPP (Jaccard) – Group – Timepoint 2"
  ) %>%
  kable_styling(latex_options = "hold_position")

# (Opcional) Print bruto para inspeção interativa
print(anosim2)
print(mrpp2)

```
ANOSIM (Jaccard, Timepoint 2)
R statistic: -0.05087

This is a negative value, indicating that the average rank of dissimilarity within groups is actually greater than between groups. In other words, samples within the same group are not more similar to each other than samples from different groups—in fact, the opposite (but the effect is very weak).

Significance (p-value): 0.966

This is much greater than 0.05, so the result is not significant.

Interpretation:
There is no evidence of group separation based on the Jaccard dissimilarity in Timepoint 2. The grouping variable ("Group") does not explain any difference in community composition, according to ANOSIM.

MRPP (Jaccard, Timepoint 2)
A (chance-corrected within-group agreement): 0.00036

The A statistic measures within-group agreement compared to random expectation.

A value near 0 means that within-group similarity is about what would be expected by chance.

Observed delta: 0.8232

This is the weighted mean within-group distance.

Expected delta: 0.8235

The expected mean within-group distance under the null hypothesis.

p-value: 0.418

Not significant (p > 0.05).

Interpretation:
There is no evidence of difference between groups (i.e., the null hypothesis of no group structure cannot be rejected).

### 3.2.2 Interaction
```{r beta_div_stat_2, eval=T, echo=F}
# --- 0) Required packages ---
library(phyloseq)
library(compositions)
library(vegan)
library(permute)
library(dplyr)
library(broom)
library(knitr)
library(kableExtra)

# --- 1) Load phyloseq and metadata ---
ps   <- readRDS("ps1.dna.rds")
meta <- sample_data(ps) %>%
  as("data.frame") %>%
  mutate(
    Group            = factor(Group),
    Days_since_start = as.numeric(Days_since_start),
    Timepoint        = factor(Timepoint, levels = c("Timepoint1","Timepoint2")),
    GroupTP          = interaction(Group, Timepoint, sep = ":"),
    PatientID        = factor(PatientID)
  )

# --- 2) Build distance matrices ---
seq_counts <- as.data.frame(t(otu_table(ps)))
if(taxa_are_rows(ps)) seq_counts <- t(seq_counts)
ilr_ratios <- compositions::ilr(t(seq_counts))
euc_dmat   <- dist(ilr_ratios)                         # Aitchison (clr → Euclid)
jac_dmat   <- vegdist(t(seq_counts), method = "jaccard") # Jaccard

# --- 3) Permutation schemes ---
perm_block <- how(nperm = 999, blocks = meta$PatientID)  # repeated measures
perm_free  <- how(nperm = 999)                          # independent

# --- 4) PERMANOVA: Group × Days_since_start interaction ---
perm_ait_int_time <- adonis2(
  euc_dmat ~ Group * Timepoint,
  data        = meta,
  permutations = perm_block
)
perm_jac_int_time <- adonis2(
  jac_dmat ~ Group * Timepoint,
  data        = meta,
  permutations = perm_block
)

# --- 5) ANOSIM & MRPP: interaction via the combined factor GroupTP ---
anosim_ait_int <- anosim(euc_dmat, meta$GroupTP, permutations = 999)
anosim_jac_int <- anosim(jac_dmat, meta$GroupTP, permutations = 999)
mrpp_ait_int   <- mrpp(euc_dmat, meta$GroupTP, permutations = 999)
mrpp_jac_int   <- mrpp(jac_dmat, meta$GroupTP, permutations = 999)

# --- 6) Format & display results ---

# PERMANOVA tables
broom::tidy(perm_ait_int_time) %>%
  kable(digits = 3, caption = "PERMANOVA (Aitchison) — Group × Timepoint") %>%
  kable_styling(latex_options = c("hold_position","scale_down"))

broom::tidy(perm_jac_int_time) %>%
  kable(digits = 3, caption = "PERMANOVA (Jaccard) — Group × Timepoint") %>%
  kable_styling(latex_options = c("hold_position","scale_down"))

#Comente para knit
perm_ait_int_time
perm_jac_int_time

# ANOSIM results
tibble(
  Method  = c("ANOSIM Aitchison", "ANOSIM Jaccard"),
  R.stat  = c(anosim_ait_int$statistic, anosim_jac_int$statistic),
  P.value = c(anosim_ait_int$signif,    anosim_jac_int$signif)
) %>%
  kable(digits = 3, caption = "ANOSIM — Group × Timepoint interaction") %>%
  kable_styling(latex_options = c("hold_position","scale_down"))

#Comente para knit
anosim_ait_int
anosim_jac_int

# MRPP results
tibble(
  Method  = c("MRPP Aitchison", "MRPP Jaccard"),
  A.stat  = c(mrpp_ait_int$A,   mrpp_jac_int$A),
  P.value = c(mrpp_ait_int$Pvalue, mrpp_jac_int$Pvalue)
) %>%
  kable(digits = 3, caption = "MRPP — Group × Timepoint interaction") %>%
  kable_styling(latex_options = c("hold_position","scale_down"))

#Comente para knit
mrpp_ait_int
mrpp_jac_int


```

PERMANOVA (Aitchison and Jaccard, Group × Timepoint, Blocked by PatientID)
Aitchison (Euclidean on ILR-transformed data):
Model F = 0.84, R² = 0.034, p = 0.746

The model (including group, timepoint, and their interaction) explained only about 3.4% of the variation in the data, and this was not statistically significant (p = 0.746).

Interpretation: There is no evidence that group, timepoint, or their interaction explain the global variation in community composition when controlling for repeated measures (PatientID).

Jaccard:
Model F = 0.77, R² = 0.031, p = 0.567

The model explained only 3.1% of the variation in Jaccard distances, also not significant (p = 0.567).

Interpretation: Similarly, group and timepoint do not explain significant differences in microbial composition using the Jaccard metric.

ANOSIM (Euclidean & Jaccard, Group × Timepoint)
Euclidean (Aitchison):
R = 0.007, p = 0.355

The ANOSIM R value is almost zero, and the p-value is much higher than 0.05.

Interpretation: There is no separation between the groups defined by Group × Timepoint.

Jaccard:
R = -0.047, p = 0.999

The negative R and very high p-value indicate not only a lack of separation, but that within-group dissimilarity is (trivially) slightly higher than between groups—expected by chance.

Interpretation: No group structure at all.

MRPP (Euclidean & Jaccard, Group × Timepoint)
Euclidean (Aitchison):
A = -0.00396, p = 0.994

A value of A near zero (or slightly negative) means within-group agreement is no better than random.

Interpretation: No evidence of group structure.

Jaccard:
A = -0.00546, p = 0.994

Again, A is basically zero, and p is not significant.

Interpretation: No evidence of group structure for presence/absence data.

Overall Summary
All beta diversity analyses—PERMANOVA, ANOSIM, and MRPP—using both Aitchison and Jaccard distances found no evidence of significant group differences in microbial community composition when considering both group and timepoint (and their interaction), even after accounting for repeated measures by patient. In all analyses, the test statistics (F, R, A) were very close to zero, and p-values were far from significance. Thus, there is no detectable effect of group, timepoint, or their interaction on global beta diversity in this dataset.

### 3.2.3 Linear Mixed Effects models for beta diversity
```{r beta_model_euc,eval=T, echo=F}
set.seed(123)

# --- Bibliotecas ---
library(phyloseq)
library(compositions)
library(vegan)
library(ape)
library(nlme)
library(dplyr)
library(tibble)
library(knitr)
library(kableExtra)

# --- 1) Prepara o objeto phyloseq e metadados ---
# ps já carregado
meta <- sample_data(ps) %>%
  as("data.frame") %>%
  mutate(
    Group     = factor(Group),
    Timepoint = factor(Timepoint),
    PatientID = factor(PatientID)
  )

# Matriz de contagens com amostras em linhas
seq_counts <- as.data.frame(otu_table(ps))
if(!identical(rownames(seq_counts), rownames(meta))) {
  seq_counts <- seq_counts[rownames(meta), , drop = FALSE]
}

# --- 2) ILR-PCA (Aitchison) para todas as amostras ---
ilr_mat <- compositions::ilr(as.matrix(seq_counts))
pca_res <- prcomp(ilr_mat, scale. = FALSE)
pca_vars <- pca_res$sdev^2 / sum(pca_res$sdev^2)

df_pca <- data.frame(
  PC1 = pca_res$x[,1],
  PC2 = pca_res$x[,2],
  meta
)

# --- 3) PCoA Jaccard para todas as amostras ---
jac_dmat <- vegdist(seq_counts, method = "jaccard")
pcoa_jac <- ape::pcoa(jac_dmat)
jac_vars <- pcoa_jac$values$Relative_eig

df_pcoa <- data.frame(
  Axis.1 = pcoa_jac$vectors[,1],
  Axis.2 = pcoa_jac$vectors[,2],
  meta
)

# --- 4) Garante que Days_since_start está numérico ---
df_pca$Days_since_start  <- as.numeric(df_pca$Days_since_start)
df_pcoa$Days_since_start <- as.numeric(df_pcoa$Days_since_start)


df_pca$BMI_classification <- factor(df_pca$BMI_classification, levels = c("normal weight", "overweight", "obesity"))
df_pca$Antibiotic_use_.in_the_past_6_months. <- factor(df_pca$Antibiotic_use_.in_the_past_6_months., levels = c("no", "yes"))
df_pca$Alcohol_consumption <- factor(df_pca$Alcohol_consumption, levels = c("no", "yes"))


df_pcoa$BMI_classification <- factor(df_pca$BMI_classification, levels = c("normal weight", "overweight", "obesity"))
df_pcoa$Antibiotic_use_.in_the_past_6_months. <- factor(df_pca$Antibiotic_use_.in_the_past_6_months., levels = c("no", "yes"))
df_pcoa$Alcohol_consumption <- factor(df_pca$Alcohol_consumption, levels = c("no", "yes"))

# --- 5) Modelos lineares mistos para cada componente ---
model_PC1 <- lme(
  fixed = PC1 ~ Days_since_start * Group +
    Sex + BMI_classification + HbA1C +
    Hypertension + Dyslipidemia + Hypothyroidism +
    Antibiotic_use_.in_the_past_6_months. +
    Alcohol_consumption,
  random = ~ 1 | PatientID,
  data = df_pca,
  method = "REML",
  na.action = na.omit,
  control = lmeControl(maxIter=100, msMaxIter=100, opt="optim")
)

summary(model_PC1)

model_PC2 <- lme(
  fixed = PC2 ~ Days_since_start * Group +
    Sex + BMI_classification + HbA1C +
    Hypertension + Dyslipidemia + Hypothyroidism +
    Antibiotic_use_.in_the_past_6_months. +
    Alcohol_consumption,
  random = ~ 1 | PatientID,
  data = df_pca,
  method = "REML",
  na.action = na.omit,
  control = lmeControl(maxIter=100, msMaxIter=100, opt="optim")
)

summary(model_PC2)

model_A1 <- lme(
  fixed = Axis.1 ~ Days_since_start * Group +
    Sex + BMI_classification + HbA1C +
    Hypertension + Dyslipidemia + Hypothyroidism +
    Antibiotic_use_.in_the_past_6_months. +
    Alcohol_consumption,
  random = ~ 1 | PatientID,
  data = df_pcoa,
  method = "REML",
  na.action = na.omit,
  control = lmeControl(maxIter=100, msMaxIter=100, opt="optim")
)

summary(model_A1)

model_A2 <- lme(
  fixed = Axis.2 ~ Days_since_start * Group +
    Sex + BMI_classification + HbA1C +
    Hypertension + Dyslipidemia + Hypothyroidism +
    Antibiotic_use_.in_the_past_6_months. +
    Alcohol_consumption,
  random = ~ 1 | PatientID,
  data = df_pcoa,
  method = "REML",
  na.action = na.omit,
  control = lmeControl(maxIter=100, msMaxIter=100, opt="optim")
)

summary(model_A2)

# --- 6) Função para tabelas bonitas dos modelos ---
print_lme_table <- function(model, model_name) {
  sm <- summary(model)
  fe <- as.data.frame(sm$tTable, check.names = FALSE)
  fe$Term <- rownames(fe)
  fe <- fe %>%
    select(Term, everything()) %>%
    rename_with(~ c("Estimate", "Std. Error", "DF", "t value", "p value"), .cols = 2:6)

  cat("##", model_name, "- Fixed Effects\n")
  print(
    fe %>%
      knitr::kable(
        caption    = paste0(model_name, " fixed effects"),
        digits     = 3,
        booktabs   = TRUE
      ) %>%
      kableExtra::kable_styling(
        latex_options = c("hold_position", "scale_down")
      )
  )

  # Random effects variance
  vc_mat   <- as.matrix(VarCorr(model))
  sd_inter <- as.numeric(vc_mat[1, "StdDev"])
  re_df    <- tibble::tibble(
    Group    = "PatientID",
    Variance = sd_inter^2
  )

  cat("\n")
  print(
    re_df %>%
      knitr::kable(
        caption  = paste0(model_name, " random‐effects variance"),
        digits   = 3,
        booktabs = TRUE
      ) %>%
      kableExtra::kable_styling(
        latex_options = c("hold_position", "scale_down")
      )
  )

  # Correlation (Phi)
  phi_val <- try(coef(model$modelStruct$corStruct, unconstrained = FALSE), silent = TRUE)
  phi_txt <- if (inherits(phi_val, "try-error") || is.null(phi_val)) {
    "NA (no correlation structure)"
  } else {
    round(phi_val, 3)
  }
  cat("\n**Correlation (Phi):**", phi_txt, "\n\n")
}

# --- 7) Imprime as tabelas dos modelos ---
print_lme_table(model_PC1, "PC1 (Aitchison PCA)")
print_lme_table(model_PC2, "PC2 (Aitchison PCA)")
print_lme_table(model_A1, "Axis.1 (Jaccard PCoA)")
print_lme_table(model_A2, "Axis.2 (Jaccard PCoA)")

# --- clean environment (opcional) ---
# rm(list = ls(all = TRUE))

```
1. General Model Fit
All models used a random intercept for PatientID, which accounts for repeated measures and inter-individual variation.

The number of patients was 24; the number of observations was 44.

2. Random Effects
PC1: Patient-level SD = 3.89; residual SD = 1.41

PC2: Patient-level SD = 2.58; residual SD = 1.36

Axis.1: Patient-level SD = 0.16; residual SD = 0.05

Axis.2: Patient-level SD = 0.11; residual SD = 0.06

Interpretation:
There is substantial inter-individual variability (as seen in the random intercept), indicating that patient identity is a relevant source of variation for all principal components.

3. Fixed Effects – Key Points
PC1 (Aitchison PCA)
No variable reached statistical significance at the conventional p < 0.05 level.

Antibiotic_use_.in_the_past_6_months.yes had a marginally non-significant effect (estimate = +1.73, p = 0.079), suggesting a possible positive association with PC1, but this does not reach the conventional significance threshold.

All other covariates (Days_since_start, Group, Sex, BMI, HbA1C, etc.) were not significant (p > 0.1).

Interpretation:
None of the modeled variables, including group, time, and clinical covariates, were significant predictors of the first principal component of the ILR-PCA.

PC2 (Aitchison PCA)
Hypothyroidismyes was the only significant predictor (estimate = –5.55, p = 0.0317), indicating that hypothyroidism is associated with a substantial decrease in PC2.

BMI_classificationoverweight was marginal (estimate = –2.59, p = 0.080), but did not reach significance.

All other variables were not significant.

Interpretation:
Only hypothyroidism was significantly associated with the second principal component (PC2), and no effect was observed for group, time, or their interaction.

Axis.1 (Jaccard PCoA)
No variable was statistically significant.

BMI_classificationoverweight showed a trend toward a negative association (estimate = –0.109, p = 0.0996), but this is only marginal.

Interpretation:
None of the predictors explained significant variation in the first principal coordinate from Jaccard PCoA.

Axis.2 (Jaccard PCoA)
BMI_classificationoverweight (estimate = –0.177, p = 0.0112) and Hypothyroidismyes (estimate = –0.229, p = 0.044) were both significantly negatively associated with Axis.2.

Alcohol_consumptionyes was marginal (estimate = –0.117, p = 0.0911).

Interpretation:
Overweight BMI and hypothyroidism are both associated with lower values on Axis.2 of the Jaccard PCoA, suggesting an effect of these clinical factors on this component of community composition.

4. Interaction (Days_since_start:Group452)
The interaction between time and group was not significant in any model (p > 0.2 for all).

This indicates there is no evidence that the trajectory over time differs between groups for any principal component/coordinate.

5. Model Residuals
The standardized residuals for all models were well within the usual range (–1.6 to +1.4), suggesting no gross violation of model assumptions.

Summary:
In linear mixed-effects models analyzing the first two principal components from ILR-PCA and Jaccard PCoA, no significant effects were observed for the main grouping variable, time, or their interaction. Notably, hypothyroidism was significantly associated with PC2 (Aitchison) and Axis.2 (Jaccard), and overweight BMI also negatively affected Axis.2. Patient identity accounted for a considerable proportion of variance, but overall, group and time did not explain differences in community structure in these ordination spaces.
\FloatBarrier

# 4.0 Differential Abundance (MaAsLin2)
## 4.1 Interaction
```{r diff_abun_maaslin, eval=F, echo=F}
library(microbiomeutilities)

# 0) Paths & output directory
path    <- '/home/local.hcpa.ufrgs.br/olovison/Projects/Tasso_et_al_2025/Analysis'
out_dir <- file.path(path, "Differential_abundance")
dir.create(out_dir, showWarnings = FALSE, recursive = TRUE)

# 1) Load phyloseq and prepare inputs
ps0 <- readRDS("ps1.dna.rds")
ps  <- format_to_besthit(ps0)

# 1a) Feature table: samples × taxa
feat <- as.data.frame(otu_table(ps))
if (taxa_are_rows(ps)) feat <- t(feat)

# 1b) Metadata
meta <- microbiome::meta(ps)

# 1c) Create Group × time interaction
meta$Group_Timepoint <- interaction(meta$Group, meta$Timepoint, sep=".")

# Padronizar: substituir "" por NA
meta$BMI_classification[meta$BMI_classification == ""] <- NA
meta$Hypertension[meta$Hypertension == ""] <- NA
meta$Dyslipidemia[meta$Dyslipidemia == ""] <- NA
meta$Hypothyroidism[meta$Hypothyroidism == ""] <- NA
meta$Antibiotic_use_.in_the_past_6_months.[meta$Antibiotic_use_.in_the_past_6_months. == ""] <- NA
meta$Alcohol_consumption[meta$Alcohol_consumption == ""] <- NA

# Converter para fator (ou numérico, no caso de HbA1C)
meta$BMI_classification <- as.factor(meta$BMI_classification)
meta$Hypertension <- as.factor(meta$Hypertension)
meta$Dyslipidemia <- as.factor(meta$Dyslipidemia)
meta$Hypothyroidism <- as.factor(meta$Hypothyroidism)
meta$Antibiotic_use_.in_the_past_6_months. <- as.factor(meta$Antibiotic_use_.in_the_past_6_months.)
meta$Alcohol_consumption <- as.factor(meta$Alcohol_consumption)
meta$HbA1C <- as.numeric(meta$HbA1C)
meta$Group <- as.factor(meta$Group)

# Atualizar os metadados no phyloseq
sample_data(ps) <- sample_data(meta)

# 2) Run MaAsLin2 with all covariates
library(Maaslin2)
fit_data <- Maaslin2(
  input_data       = feat,
  input_metadata   = meta,
  output            = out_dir,
  fixed_effects    = c(
    "Group",
    "Timepoint",
    "Group_Timepoint",
    "BMI_classification",
    "HbA1C",
    "Hypertension",
    "Dyslipidemia",
    "Hypothyroidism",
    "Antibiotic_use_.in_the_past_6_months.",
    "Alcohol_consumption"
  ),
  random_effects   = "PatientID",
  reference        = c(
    "Group,151",
    "Timepoint,Timepoint1",
    "Group_Timepoint,151.Timepoint1",
    "BMI_classification,normal weight",
    "Hypertension,no",
    "Dyslipidemia,no",
    "Hypothyroidism,no",
    "Antibiotic_use_.in_the_past_6_months.,no",
    "Alcohol_consumption,no"
  ),
  normalization    = "CLR",
  transform         = "LOG",
  analysis_method  = "LM",
  min_prevalence   = 0.1,
  min_abundance    = 0.1,
  correction       = "BH",
  standardize      = TRUE,
  cores            = 8
)

# 3) Clean up
rm(list = ls(all = TRUE))
```
https://www.midasfieldguide.com/guide/fieldguide/genus/nk4a214_group

```{r maaslin2_cat_bar_interaction_individual, eval=TRUE, message=FALSE, warning=FALSE, echo=FALSE, fig.align='center', fig.width=8, fig.height=6}
#  ================================================
#  Differential‐Abundance Barplots (Maaslin2 output)
#  ================================================
#  1) Libraries + directory setup
#  ================================================
library(readr)
library(dplyr)
library(ggplot2)
library(forcats)
library(grid)      # for unit()
library(stringr)   # for str_replace_all()

# (a) Base path & output directory:
base_path <- '/home/local.hcpa.ufrgs.br/olovison/Projects/Tasso_et_al_2025/Analysis'
out_dir   <- file.path(base_path, "Differential_abundance")
dir.create(out_dir, showWarnings = FALSE, recursive = TRUE)

#  ================================================
#  2) Read MaAsLin2 “significant_results.tsv”
#     (this file must have been written by Maaslin2)
#  ================================================
res <- read_tsv(
  file.path(out_dir, "significant_results.tsv"),
  show_col_types = FALSE
)

#  Check columns quickly:
#  feature   metadata   value   coef   stderr   qval   ... 
#  -----------------------------------------------------
#  “feature”   = the taxonomic feature name (e.g. genus)
#  “metadata”  = which variable was the coefficient (e.g. “Group” or “Timepoint” etc.)
#  “value”     = the category within that metadata (e.g. “452” or “Timepoint2” etc.)
#  “coef”      = the estimated log₂ fold‐change (LFC) for (value vs reference)
#  “qval”      = FDR‐corrected p‐value

#  ================================================
#  3) Define reference‐levels for each metadata
#     (Change these if you used different references in Maaslin2)
#  ================================================
ref_values <- c(
  Group              = "151",          # e.g. Group’s reference was “151”
  Timepoint          = "Timepoint1",   # Timepoint’s reference was “Timepoint1”
  Group_Timepoint    = "151.Timepoint1",# Group_Timepoint’s reference was “151.Timepoint1”
  BMI_classification = "normal weight",
  Hypertension       = "no",
  Dyslipidemia       = "no",
  Hypothyroidism     = "no",
  Antibiotic_use_.in_the_past_6_months. = "no",
  Alcohol_consumption = "no"
  )


#  ================================================
#  4) Keep only the three variables we want to plot
#     (Group, Timepoint, Group_Timepoint)
#  ================================================
#    Filter out any metadata lines that are NOT exactly "Group", "Timepoint", or "Group_Timepoint".
plot_vars <- c("Group", 
               "Timepoint", 
               "Group_Timepoint", 
               "BMI_classification", 
               "Hypertension", 
               "Dyslipidemia",
               "Hypothyroidism",
               "Antibiotic_use_.in_the_past_6_months.",
               "Alcohol_consumption")
df_keep   <- res %>%
  filter(metadata %in% plot_vars)

#  If you also want to filter strictly qval < 0.05, uncomment:
# df_keep <- df_keep %>% filter(qval < 0.05)

#  ================================================
#  5) For each (metadata,value) combination,
#     pick up to the top 10 features by q‐value
#  ================================================
topn_per_combo <- df_keep %>%
  arrange(metadata, value, qval) %>%               # sort by metadata → value → ascending qval
  group_by(metadata, value) %>%
  slice_head(n = 10) %>%                            # pick top 10 (or fewer) per (metadata,value)
  ungroup()

#  If you prefer “up to 10 most significant” even if fewer have q < 0.05, you can pre‐filter qval:
# topn_per_combo <- df_keep %>%
#   filter(qval < 0.05) %>%
#   arrange(metadata, value, qval) %>%
#   group_by(metadata, value) %>%
#   slice_head(n = 10) %>%
#   ungroup()

#  ================================================
#  6) Build a small helper function to draw one bar‐plot
#  ================================================
make_barplot_for_combo <- function(df_subset) {
  # df_subset has columns: feature, metadata, value, coef, stderr, qval, ...
  # Step 1: rename “coef” → “lfc”, compute “direction”, reorder factor:
  df_plot <- df_subset %>%
    rename(lfc = coef) %>%
    mutate(
      direction = if_else(lfc >= 0, "Positive LFC", "Negative LFC"),
      feature   = fct_reorder(feature, abs(lfc))
    )
  # Step 2: figure out the (metadata,value) → reference, to label the title:
  mvar  <- unique(df_plot$metadata)   # e.g. "Group"
  val   <- unique(df_plot$value)      # e.g. "452" or "Timepoint2" or "452.Timepoint2"
  # Look up reference:
  ref   <- ref_values[mvar]
  # Build a title string like “Group: 452 vs 151”
  title_text <- sprintf("%s: %s vs %s", mvar, val, ref)

  # Step 3: draw
  p <- ggplot(df_plot, aes(x = lfc, y = feature, fill = direction)) +
    geom_col(width = 0.6, color = "black") +
    scale_fill_manual(
      values = c("Positive LFC" = "darkslategray3", 
                 "Negative LFC" = "coral"),
      name = "Direction"
    ) +
    labs(
      title = title_text,
      x     = expression(Log[2]~fold~change),
      y     = NULL
    ) +
    theme_bw(base_size = 8) +
    theme(
      plot.title       = element_text(face = "bold", hjust = 0.5),
      axis.text.y      = element_text(face = "italic", size = 8),
      axis.text.x      = element_text(size =  8),
      legend.position  = "bottom",
      plot.margin      = unit(c(0.8,0.8,0.8,0.8), "lines")
    )

  return(p)
}

#  ================================================
#  7) Loop over each (metadata,value) and save one plot
#  ================================================
#    We'll build a unique filename for each plot as “diffabund_<metadata>_<value>.png/pdf”.

# Obtain the distinct (metadata,value) pairs in our topn list:
combos <- topn_per_combo %>%
  distinct(metadata, value) %>%
  arrange(metadata, value)

for(i in seq_len(nrow(combos))) {
  mvar <- combos$metadata[i]
  val  <- combos$value[i]

  # Subset the top-10 table for exactly that metadata–value
  df_subset <- topn_per_combo %>%
    filter(metadata == mvar, value == val)

  # If no rows, skip
  if(nrow(df_subset) == 0) next

  # Build the barplot
  p <- make_barplot_for_combo(df_subset)

  # Clean up “unsafe” characters in mvar/val for filenames:
  mvar_clean <- str_replace_all(mvar, "[^A-Za-z0-9_]", "_")
  val_clean  <- str_replace_all(val,  "[^A-Za-z0-9_\\.]", "_")

  # Save PNG and PDF
  pngfile <- file.path(out_dir, sprintf("diffabund_%s_%s.png", mvar_clean, val_clean))
  pdffile <- file.path(out_dir, sprintf("diffabund_%s_%s.pdf", mvar_clean, val_clean))

  ggsave(pngfile, plot = p, width = 6, height = 4, units = "in", dpi = 300)
  ggsave(pdffile, plot = p, width = 6, height = 4, units = "in", dpi = 300)
}

# limpa ambiente
rm(list=ls(all=TRUE))
#  ================================================
#  Done. Now you should see one bar‐plot per (metadata,value).
#  ================================================
```

# 5.0 PICRUSt2
## 5.1 Exporting the data
The data is exported for PICRUSt2 algorithm analysis.
```{r exp_picrust2, eval=FALSE, echo=FALSE}
path <- '/home/local.hcpa.ufrgs.br/olovison/Projects/Tasso_et_al_2025/Analysis'
picrust2 = paste(path,"/Picrust2/",sep = "")
dir.create(picrust2)

ps <- readRDS("ps1.dna.rds")

# Exportar taxonomy table como "tax.txt" Somente necessário se for usar o qiime2
tax<-as(tax_table(ps),"matrix")
tax_cols <- colnames(tax)
tax<-as.data.frame(tax)
tax$taxonomy<-do.call(paste, c(tax[tax_cols], sep=";"))
for(co in tax_cols) tax[co]<-NULL
FileName <- paste(picrust2,"/tax.txt", sep = "")
write.table(tax, FileName, quote=FALSE, col.names=FALSE, sep="\t")

#Exportar o fasta das sequências
sequences <- refseq(ps)
sequences_char <- as.character(sequences)
fasta_headers <- paste(">", names(sequences), sep="")
fasta_content <- paste(fasta_headers, sequences_char, sep="\n")
FileName <- paste(picrust2,"/sequences.fasta", sep = "")
writeLines(fasta_content, FileName)

# Exportar feature/OTU table
# Formato biom file
library(biomformat);packageVersion("biomformat")
otu<-t(as(otu_table(ps),"matrix")) # 't' para transpor se taxa_are_rows=FALSE, que geralmente é o nosso caso
#if taxa_are_rows=TRUE
#otu<-as(otu_table(ps),"matrix"))
otu_biom<-make_biom(data=otu)
FileName <- paste(picrust2,"/otu_biom.biom", sep = "")
write_biom(otu_biom,FileName)

# Como txt (caso dê algum erro com o formato biom) a partir do dado de pré-processamento
#write.table(t(seqtab), "seqtab.txt", sep="\t", row.names=TRUE, col.names=NA, quote=FALSE)
#ou do objeto phyloseq, 't' se taxa_are_rows=FALSE (geralmente o nosso caso), sem 't' se taxa_are_rows=TRUE
#FileName <- paste(picrust2,"/seqtab.txt", sep = "")
#write.table(t(otu_table(ps), FileName,sep="\t", row.names=TRUE, col.names=NA, quote=FALSE)

#Exportar metadados (se a sua tabela de metadados já está adequadamente formatada, pode usar ela em formato csv, mas como geralmente tratamos as variáveis dentro do objeto phyloseq, o ideal é exportar)
metadata <- microbiome::meta(ps)
FileName <- paste(picrust2,"/sample_metadata.txt", sep = "")
write.table(metadata,FileName, sep="\t", row.names=FALSE, col.names=TRUE, quote=FALSE)

# clean environment
rm(list = ls(all = TRUE))
#Os arquivos gerados devem ser utilizados para o pipeline do Picrust2 no terminal, e o output do Picrust2 deve ser utilizado nos chunks abaixo para análises e figuras.
```

## 5.2 Metabolic Prediction - MetaCyc Pathways
```{r picrust2_output_metacyc, eval=FALSE, echo=F}
# Carregue o dataset MetaCyc_pathway_map
data("MetaCyc_pathway_map")

path <- '/home/local.hcpa.ufrgs.br/olovison/Projects/Tasso_et_al_2025/Analysis'
picrust2_metacyc_maaslin = paste(path,"/Picrust2_metacyc_maaslin/",sep = "")
dir.create(picrust2_metacyc_maaslin)

ps <- readRDS("ps1.dna.rds")

# Carregue os dados de abundância funcional
# Por exemplo, para dados de vias MetaCyc:
metacyc_abundance <- read.table("/home/local.hcpa.ufrgs.br/olovison/Projects/Tasso_et_al_2025/Analysis/path_abun_unstrat.tsv", header = TRUE, row.names = 1, sep = "\t")

# Adicione uma coluna com os IDs das vias em cada df
metacyc_abundance$pathway_id <- rownames(metacyc_abundance)
MetaCyc_pathway_map$pathway_name <- rownames(MetaCyc_pathway_map)

#Anotando as rotas metabólicas
# Mescle com o mapeamento para obter as descrições
annotated_metacyc_abundance <- merge(
  metacyc_abundance,
  MetaCyc_pathway_map,
  by.x = "pathway_id",
  by.y = "pathway_name",
  all.x = TRUE
)

# Se quiser exportar para um arquivo Excel
FileName <- paste(picrust2_metacyc_maaslin,"/Annotated metacyc abundances.xlsx", sep = "")
write_xlsx(annotated_metacyc_abundance,FileName)

# Ajuste os nomes das linhas para corresponder à coluna 'pathway'
rownames(annotated_metacyc_abundance) <- annotated_metacyc_abundance$pathway

# Remover as colunas não-numéricas do dataframe
annotated_metacyc_abundance$pathway_id <- NULL
annotated_metacyc_abundance$Superclass1 <- NULL
annotated_metacyc_abundance$Superclass2 <- NULL
annotated_metacyc_abundance$pathway <- NULL

# Carregue a tabela de metadados
metadata <- microbiome::meta(ps)

# Criando uma variável de interação (Maaslin2 não aceita interação na modelagem)
metadata$Group_Age_interaction <- interaction(metadata$Group, metadata$Age)

# Executar o MaAsLin2
fit_data <- Maaslin2(
    input_data = annotated_metacyc_abundance,
    input_metadata = metadata,
    output = picrust2_metacyc_maaslin,
    fixed_effects = c("Group", "Age", "Group_Age_interaction"),
    random_effects = "PatientID",
    reference = c("Group,452;Age,20;Group_Age_interaction,452.20"),
    normalization = "CLR",
    transform = "LOG",      # Transformação logarítmica
    analysis_method = "LM", # Modelo Linear
    min_prevalence = 0.1,
    min_abundance = 0.01,
    correction = "BH",
    standardize = TRUE,
    cores = 20
)

# clean environment
rm(list = ls(all = TRUE))
```

### 6.0 Session info
```{r session_info, eval=TRUE, echo=F}
sessionInfo()
```